\Sexpr{set_parent('STAT241-S19.Rnw')}

\Chapter{Graphical Summaries of Data}

\section{Getting Started With \RStudio}

\begin{figure}
\begin{center}
\includegraphics[width=.85\textwidth]{images/RStudio-Welcome2}
\end{center}
\caption{Welcome to \Rstudio.}
\label{fig:Rstudio-welcome}%
\end{figure}

\RStudio{} is an integrated development environment (IDE) for \R,  
a freely available language and environment for statistical computing and graphics.
Both \R and \RStudio{} are freely available for Mac, PC, and Linux.  

We have set up an RStudio server on campus, which allows you to run R in a web browser on any computer without installing the software yourself.  Your session is restored each time you log in, so you can work on multiple computers without losing your work when you move from one to the other.  The RStudio server is the recommended interface for using R and RStudio for this course. You can access the \RStudio{} server via a web browser.  (For best results, avoid 
Internet Explorer.)

If you prefer to install R and RStudio directly on your own computer, you can get R at \url{<http://cran.r-project.org>} and RStudio at \url{<http://rstudio.org/>}.    

To access the Calvin \RStudio{} server, go to \url{http://rstudio.calvin.edu}.

\subsection{Logging in}
When you navigate to the \RStudio{} server, you will be prompted to login.  
% Your login and password are both your Calvin
% userid.  
Your login and password are the same ones you would use for the Calvin CS servers, if you have previously taken a CS course. If not, you should have received an email at the beginning of the semester from ``RStudio account creation robot" to your Calvin email account, telling you how to set up your password. 

If you have forgotten your password and need to reset it, visit \url{https://cs.calvin.edu/sysadmin/linux-forgotpassword.php}

Once you are logged in, you will see something like 
Figure~\ref{fig:Rstudio-welcome}.

% To change your password:
% \begin{enumerate}
% 	\item From the \tab{Tools} menu, select \tab{Shell...}
% 	\item
% 		Type \code{yppasswd}
% 	\item
% 		You will be prompted for your old password, then your new password twice.
% 	\item
% 		If you give a sufficiently strong new password, then
% 		you will receive notice that your password has been reset.  
% 		If there was a problem, you will see a message about it and can try again.
% 	\item
% 		Once you have reset your password, click on \tab{Close} to close the 
% 		shell and get back to \RStudio.
% \end{enumerate}

\subsection{Using R as a calculator}

Notice that \Rstudio\ divides its world into four panels.  Several of the panels
are further subdivided into multiple tabs.
The \textbf{Console} panel is where we type commands that \R\ will execute. 

\R\ can be used as a calculator.  Try typing the following commands in the console panel.
\Rindex{sqrt()}%
\Rindex{log()}%
\Rindex{log10()}%
<<arithmetic2>>=
5 + 3
15.3 * 23.4
sqrt(16)
@

You can save values to named variables for later reuse
<<variables2,tidy=FALSE>>=
product = 15.3 * 23.4       # save result
product                     # show the result
product <- 15.3 * 23.4      # <- is assignment operator, same as =
product                     
.5 * product                # half of the product
log(product)                # (natural) log of the product
log10(product)              # base 10 log of the product
log(product,base=2)         # base 2 log of the product
@

The semi-colon can be used to place multiple commands on one line.  
One frequent use of the semi-colon is to save and print a value all 
in one line of code:
<<variables-semi2,tidy=FALSE>>=
15.3 * 23.4 -> product; product    # save result and show it
@

\subsection{Loading packages}

\R\ is divided up into packages.  You can think of the packages as software toolkits designed to do 
particular jobs.  A few of these, known as ``base \R", are loaded every time you
run \R, but most have to be selected.  This way you only have as much of \R\ as you
need.  There are two steps to follow before you can use a package in \R :

\begin{enumerate}
\item{Install the package.} This operation downloads the relevant files to your computer, and lets \R\ know where they are located.  It does \textit{not} give the current \R\ session permission to use the tools contained in the package!  The packages you will need for work in this course have already been installed on the Calvin \Rstudio\ server. For this course, you will probably not need to install any packages yourself, unless you are using a local copy of \R\ and \RStudio\ installed on your own computer.  If you need to install packages, an easy way to do it is to use the \textbf{Packages} tab in the lower right panel of \RStudio. Just click on \textbf{Install} (upper left corner of the \textbf{Packages} tab) and then type the name of the package.
\item{Load the package.} This operation gives the current \R\ session permission to access and use the tools contained in the package.  Even if you are using the \RStudio server, you will often need to load required packages at the beginning of each \R\ session.  
\end{enumerate}

You an also load packages with commands like:
<<load-package>>=
require(mosaic)       # loads the mosaic package if it is not already loaded
library(mosaic)       # library() and require() are essentially equivalent
@

\subsection{Four Things to Know About \R}
\begin{enumerate}
\item \R\ is case-sensitive

If you mis-capitalize something in \R, it won't do what you want.

\item 
Functions in \R\ use the following syntax:
<<function-syntax,eval=FALSE>>=
functionname( argument1, argument2, ... )
@
\vspace{-5mm}
\begin{itemize}
\item The arguments are \underline{always} \emph{surrounded by (round) parentheses} and 
\emph{separated by commas}.

Some functions (like \function{data()}) 
have no required arguments, but you still need the parentheses.

\item
If you type a function name without the parentheses, you will see the \emph{code} for that
function printed out to the console window -- which probably isn't what you want at this point.
\end{itemize}

\item Hit ESCAPE to break out of a mess.
	
	If you get into some sort of mess typing (usually indicated by extra '$+$' 
	signs along the left edge, indicating that \R\ is waiting for more 
	input -- perhaps because you have some sort of error in what has gone before), 
	you can hit the escape key to get back to a clean prompt.
\end{enumerate}


\section{Data in \R}

\subsection{Data Frames}
Most often, data sets in \R\ are stored in a structure called a 
\term{data frame}.  A data frame is designed to hold ``rectangular data".  The people or things
being measured or observed are called \term{cases} (or subjects when 
they are people).  For measurements collected over time, the cases would be the individual 
time-points at which data points were collected. Each case is represented by one row in the data frame.
The different pieces of information recorded for each case are stored in
separate columns, called \term{variables}.  

\subsection{Data in Packages}
There are a number of data sets built into \R\
and many more that come in various add-on packages.  

You can see a list of data sets in a particular package like this:
<<datasets,eval=FALSE>>=
data(package="mosaicData")
data(package="DAAG")
@

You can find a longer list of all data sets available in any loaded package
using 
<<eval=FALSE>>=
data()
@


\subsection{The HELPrct data set}
The \dataframe{HELPrct} data frame from the \pkg{mosaic} package
contains data from the Health Evaluation and Linkage to Primary Care
randomized clinical trial.  You can find out more about the study and
the data in this data frame by typing
<<HELPrcthelp,eval=FALSE,tidy=FALSE>>=
?HELPrct
@

Among other things, this will tell us something about the subjects (cases) in
this study:
\begin{quote}
	Eligible subjects were adults, who spoke Spanish or English, reported
	alcohol, heroin or cocaine as their first or second drug of choice, resided
	in proximity to the primary care clinic to which they would be referred or
	were homeless. Patients with established primary care relationships they
	planned to continue, significant dementia, specific plans to leave the
	Boston area that would prevent research participation, failure to provide
	contact information for tracking purposes, or pregnancy were excluded.

Subjects were interviewed at baseline during their detoxification stay and
follow-up interviews were undertaken every 6 months for 2 years.
\end{quote}

It is often handy to look at the first few rows of a data frame.  It will
show you the names of the variables and the kind of data in them. You can also ask R to count the rows and columns in the dataset.
<<headHELP>>=
head(HELPrct)
nrow(HELPrct)
ncol(HELPrct)
@

The commands and \R\ output above tell us that there are \Sexpr{nrow(HELPrct)} observational
units in this data set and \Sexpr{ncol(HELPrct)} variables.
That's plenty of variables to get us started with exploration of data.

\subsection{The KidsFeet data set}
Here is another data set in the \pkg{mosaic} package, and another way to get a quick look at the variable names and data types in a dataset:
<<>>=
glimpse(KidsFeet)
@

\subsection{The oldfaith data set}
A final example data set comes from the \pkg{alr3} package.  This package is probably not 
loaded (unless you already loaded it).  You can load it from the \tab{Packages} tab or
by typing the command
<<>>=
require(alr3)
@
Once you have done that, you will have access to the data set containing information about
eruptions of Old Faithful, a geyser in Yellowstone National Park.
<<>>=
glimpse(oldfaith)
@

If you want to know the size of your data set, you can ask it how many rows and columns it has
with
\function{nrow}, \function{ncol}, or \function{dim}:
<<>>=
nrow(oldfaith)
ncol(oldfaith)
dim(oldfaith)
@
In this case we have 270 observations of each of two variables.
In a data frame, the cases are always in the rows and the variables
are always in the columns.  If you create data for use in \R\ (or most other 
statistical packages), you need to make sure your data are also in this shape.


\subsection{Using your own data}

For detailed examples of how to import data from a Google Sheet or how to upload a data set to RStudio, please review the relevant sections of the tutorial at \url{http://rsconnect.calvin.edu:3939/connect/#/apps/44/access}

\section{Graphing the Distribution of One Variable}

A \textbf{distribution} tells which values a variable takes on, 
and with what frequency.  That is, the distribution answers two 
questions:
\begin{itemize}
	\item What values?  
	\item How often?
\end{itemize}

Several standard statistical graphs can help us see 
distributions visually.  

The general syntax for making a graph or numerical summary
of one variable in a data frame is
<<eval=FALSE>>=
plotname( ~ variable, data=dataName )
@
In other words, there are three pieces of information we must provide to 
\R\ in order to get the plot we want:
\begin{itemize}
	\item
		The kind of plot (\function{gf_histogram()}, \function{gf_bar()}, 
		\function{gf_boxplot()}, etc.) 
	\item
		The name(s) of the variable(s) to plot
	\item
		The name of the data frame this variable is a part of.
\end{itemize}

Note: The same syntax works for numerical summaries as well -- thanks to the \pkg{mosaic}
package we can apply the same syntax for 
		\function{mean}, \function{median}, \function{sd},
		\function{var}, \function{max}, \function{min}, etc.
		Later we will use this syntax again to fit linear and 
		nonlinear models to data.

\subsection{Histograms (and density plots) for quantitative variables}

Histograms are a way of displaying the distribution of a quantitative 
variable.


Here are a couple examples:
<<histogram>>=
gf_histogram( ~ Duration, data=oldfaith )
gf_histogram( ~ age, data=HELPrct )
@

We can control the number of bins using the \option{bins} 
argument. The number of bins can make a histogram look quite different, and we aim to avoid using too few or too many.
<<histogram2, fig.width=3,out.width='.3\\textwidth'>>=
gf_histogram( ~ Duration, data=oldfaith, n=15 )
gf_histogram( ~ Duration, data=oldfaith, n=30 )
gf_histogram( ~ Duration, data=oldfaith, n=50 )
@

Another way to control the position of the bins is to set their width (instead of the overall number of bins). For example,

<<xhistogram,fig.width=3,out.width=".3\\textwidth">>=
gf_histogram( ~ Duration, data=oldfaith, binwidth=60 )
gf_histogram( ~ Duration, data=oldfaith, binwidth=20 )
gf_histogram( ~ Duration, data=oldfaith, binwidth=5 )
@

\R\ also provides a ``smooth'' version called a density plot; just change 
the function name from \function{gf_histogram()} to 
\function{gf_density()}.
<<densityplot>>=
gf_density( ~ Duration, data=oldfaith )
@


\subsection{The shape of a distribution}

If we make a histogram of our data, we can describe the overall shape of the distribution.
Keep in mind that the shape of a particular histogram may depend on the choice of bins.
Choosing too many or too few bins can hide the true shape of the distribution.  (When in doubt, compare several
histograms with different bin settings before you decide which one provides the most informative
summary of the data.)

Here are some words we use to describe shapes of distributions.
\begin{description}
\item[symmetric] The left and right sides are mirror images of each other.
\item[skewed] The distribution stretches out farther in one direction than in the other.  
(We say the distribution is skewed toward the long tail. So right-skewed 
(also known as positive-skewed)
data have a ``fat right tail" -- more observations of larger values than of small ones.)
\item[uniform] The heights of all the bars are (roughly) the same.  
(So the data are equally likely to be anywhere within some range.)
\item[unimodal] There is one major ``peak'' where there is a lot of data.
\item[bimodal] There are two peaks.
\item[multimodal] There are more than two peaks.
\item[outlier] An observation that does not fit the overall pattern of the rest of 
the data.
\end{description}



We'll learn about another graph used for quantitative variables 
(a boxplot, \function{gf_boxplot()} in \R) soon.

\subsection{Bar graphs for categorical variables}

Bar graphs are a way of displaying the distribution of a categorical variable.

<<bargraph>>=
gf_bar( ~ substance, data=HELPrct) 
gf_bar( ~ substance, data=HELPrct) %>%
  gf_refine(coord_flip())
@

A side note: we usually prefer bar graphs to pie charts in this course.
Many data analysts argue that pie charts are difficult to read and interpret,
and often use space ineffectively, especially if they are divided into more than two slices.  Unless you are \textit{sure} 
there is a good reason to use one, don't.  See \url{http://rsconnect.calvin.edu:3939/connect/#/apps/94/access} for and example if you want to give it a try.

\section{Looking at Multiple Variables at Once}

\subsection{Conditional plots}
The formula for a plot can be extended to create multiple
panels based on a ``condition'', often given by another variable.  The 
general syntax for this becomes
<<eval=FALSE>>=
plotname( ~ variable | condition, data=dataName )
@

For example, we might like to see how the ages of homeless and housed people compare 
in the HELP study.

<<compare-ages>>=
gf_histogram( ~ age | homeless, data=HELPrct, binwidth=5)
@


We can do the same thing for bar graphs.

<<substance-by-sex>>=
gf_bar( ~ substance | homeless, data=HELPrct)
@

\subsection{Stacked or Side-By-Side Bar Graphs}
Instead of showing bar graphs for different groups in separate panels or ``facets", as shown above, we might want to use a stacked bar graph:

<<substance-by-sex-stacked>>=
gf_bar( ~ substance, fill = ~ homeless, data = HELPrct)
@

Similarly, we can use a grouped bar graph with side-by-side sets of bars:

<<substance-by-sex-sbs>>=
gf_bar( ~ substance, fill = ~ homeless, position = 'dodge', data = HELPrct)
@

\subsection{Side-by-side Density Curves}
We can do something similar with density curves to show individual curves for each group:
<<density-groups>>=
gf_density(~age, fill = ~homeless, data=HELPrct)
@

\subsection{Scatterplots}

The most common way to look at two quantitative variables is with a 
scatter plot.  The function for this is \function{gf_point()}, 
and the basic syntax is

<<xyplot-syntax, eval=FALSE>>=
gf_point( yvar ~ xvar, data=datasetName)
@

Notice that now we have something on both sides of the \~{} since we need to tell
\R\ about two variables.  

<<xyplot1, tidy=FALSE>>=
head(iris) # data on iris plants
gf_point( Sepal.Length ~ Sepal.Width, data=iris )
@

Grouping and conditioning work just as before and can be used to see the relationship
between sepal length and sepal width broken down by species of iris plant.
With large data set, it can be helpful to make the dots semi-transparent so it is
easier to see where there are overlaps.  This is done with \argument{alpha}.
We can also make the dots smaller (or larger) using \argument{size} (multaplicative; for example, 2 means double the usual size).
<<xyplot2,fig.width=6,fig.height=3,tidy=FALSE>>=
gf_point( Sepal.Length ~ Sepal.Width | Species, data=iris, alpha=.6, size=.5 )
gf_point( Sepal.Length ~ Sepal.Width, color = ~ Species, shape = ~ Species, data=iris,
          alpha=.3, size = 2)
@

\section{Reproducible Research}

When starting to learn to use \R\ for data analysis, it may be tempting to work 
by typing commands into the \R\ console directly, or maybe by copying and pasting commands
from some other source (for example, these notes, a website, etc.).

There are many reasons to avoid working this way, including:
\begin{itemize}
	\item It is tedious, unless there is very little to type, or to copy and paste.
	\item It is error-prone -- it's easy to copy too little or too much, or to grab the wrong thing,
		or to copy when you want to cut or cut when you want to copy.
	\item
		If something changes, you have to start all over.
	\item
		You have no record of what you did (unless you are an unusual person who
		takes detailed notes about everything you copied and pasted, or typed into the \R\ console).
\end{itemize}
So while copy and paste seems easy and convenient at first, it is not \emph{reproducible}.  Reproducible, here,
means something that can easily be repeated in exactly the same way (or with some desired modification), because
the exact procedure that was followed has been clearly documented in a format that is simple to access.
Reproducibility is important when projects are large, when it is important to have record of 
exactly what was done, or when the same analysis will be applied to multiple data sets (or a data set
that is growing over time).

\RStudio\ makes it easy to use techniques of reproducible research to create
documents that include text, \R\ commands, \R\ output, and \R\ graphics.  

\subsection{R Markdown}
One simple way to do reproducible work is to use a format called R Markdown.
Markdown is a simple
mark up language that allows for a few basic improvements on plain text
(section headers, bulleted lists, numbered lists, bold, italics, etc.)  R
Markdown adds the ability to mix in the \R\ stuff (\R\ commands and output,
including figures).  
The end product is a PDF or an HTML file, so it is especially good for producing web 
documents.\footnote{You can actually mix in arbirary HTML and even css, so if you
are good at HTML, you can have quite a bit of control over how things look.  Here we
will focus on the basics.}

\subsubsection{Creating a new document}
To create a new R Markdown document in \RStudio, go to ``File", ``New File", then ``R Markdown":
\begin{center}
	\includegraphics[width=3in]{images/NewRMarkdown}
\end{center}

A small pop-up window will appear; a great choice for this course is to select``From Template" and then ``Template for STAT 241 Homework".
\begin{center}
  \includegraphics[width=3in]{images/NewRMarkdownPopup}
\end{center}

When you do this, a file editing pane will open with a template inserted.  If
you click on ``Knit", \RStudio\ will turn this into a PDF file and
display it for you.  Give it a try.  You will be asked to name your file if you
haven't already done so.  If you are using the \RStudio\ server in a browser,
then your file will live on the server (``in the cloud'') rather than on your
computer.

If you look at the template file you will see that the file has two kinds of
sections.  Some of this file is just normal text (with some extra symbols to
make things bold, add in headings, etc.)  You can get a list of all of these
mark up options by selecting the ``Markdown Quick Reference" in the Help menu (at the top of the Markdown document in the editing pane).

\begin{center}
	\includegraphics[width=2in]{images/MardownQuickReference}
\end{center}

The second type of section is an \R\ code chunk.  These are colored differently to make them
easier to see.  You can insert a new code chunk by selecting ``Insert Chunk" from the ``Code" 
menu, or clicking the little green square with a ``C" in it (and choosing ``R").

You can put any \R\ code in these code chunks and the results (text output or graphics) as well
as the \R\ code will be displayed in your PDF or HTML file.

%There are options to do things like (a) run \R\ code without displayng it, (b) run \R\ code without
%displaying the output, (c) controling size of plots, etc., etc.  
%But for starting out, this is really all you need to know.

\subsection*{R Markdown files must be self-contained}
R Markdown files do not have access to things you have done in your console.  (This is good, else 
your document would change based on things not in the file.)  Within each R Markdown file, you must explicitly
load data, and require packages \emph{in the R Markdown file} in order to use them.  In this class,
this means that most of your R Markdown files will have a chunk near the beginning that loads required
packages and datasets.


\subsubsection{R Markdown files do not have access to the console environment}
One thing you need to remember about R Markdown documents is that the file must be self-contained.
This ensures that the document is portable.  It also means that the docuemnt does not have 
access to the things in your console environment.  All data must be loaded in the file.  
Similarly, all packages you use must also be loaded in the file.  If you start getting messages 
about objects not being found, one possible cause is that you have forgotten to get some 
data or some package loaded inside your file.  (Typos are another cause for these messages -- 
check your spelling and capitalization.)


\section{Customizing Graphics: A Few Bells and Whistles}
There are lots of arguments that control the appearance of plots created in \R.  Here are just a
few examples, some of which we have already seen.

\subsection*{Labels}

You can add a title, or change the default labels of the axes.
<<iris-xyplot-text,fig.width=3,fig.height=2.5>>=
gf_point(Sepal.Length ~ Sepal.Width, color=~Species, data=iris) %>% 
	gf_labs(title="Some Iris Data",
	        x="sepal width (cm)",
	        y="sepal length (cm)")
@


\subsection{More}
Nearly every feature of a plot can be controlled: fonts, colors,
symbols, line thicknesses, colors, etc.  These settings 
can also be collected into a theme (for example, there is a theme that makes your plots look just like they came from \textit{The Economist}).  

For details and examples, review the tutorials at \url{http://rsconnect.calvin.edu:3939/connect/#/apps/45/access} and \url{http://rsconnect.calvin.edu:3939/connect/#/apps/46/access}.

\section{Getting Help in RStudio}

\subsection{The \RStudio\ help system}
There are several ways to get \RStudio\ to help you when you forget something.
Most objects in packages have help files that you can access by typing something 
like:
<<help-questionmark,eval=FALSE,tidy=FALSE>>=
?gf_bar
?gf_point
?HELPrct
@

You can search the help system using
<<help-GR,eval=FALSE>>=
help.search('Grand Rapids')    # Does R know anything about Grand Rapids?
@
This can be useful if you don't know the name of the function or data set you 
are looking for.

\subsection{History}
If you know you have done something before, but can't remember how, you can
search your history.  The history tab shows a list of recently executed
commands.  There is also a search bar to help you find things from longer ago.

\subsection{Error messages}
When things go wrong, \R\ tries to help you out by providing an error message.
Typos are probably the most common cause of errors: for example, you might
misspell a function or argument name, forget to close a set of parentheses or 
brackets, or misplace a comma.  
One common error message is illustrated below.
<<error-message>>=
fred <- 23
frd
@
The object \code{frd} is not found because it was mistyped.  It should have
been \code{fred}.  Another common mistake is forgetting to load required packages.
If you see an ``object not found'' message, check your
typing and check to make sure that the necessary packages have been loaded.
If you get an error and can't make sense of the message, you can try copying and pasting your
command and the error message and sending to me in an email. 

\section{Graphical Summaries -- Important Ideas}

\subsection{The Most Important Template}

The plots we have created have all following a single template

\begin{center}
	\Large 
	\texttt{ \fbox{\texttt{ goal }} ( \fbox{\texttt{ formula }}, data = \fbox{\texttt{ mydata }} ) }
\end{center}
We will see this same template used again for numerical summaries and linear and non-linear 
modeling as well, so it is is important to master it.

\begin{itemize}
	\item \texttt{goal}: The name of the function generally describes your goal, 
		the thing you want the computer to produce for you.  In the case of plotting,
		it is the name of the plot.  When we do numerical summaries it will be the 
		name of the numerical summary (mean, median, etc.).
	\item
		\texttt{formula}: For plotting, the formula describes which variables are 
		used on the x-axis, the y-axis and for conditioning.  The general scheme is
<<eval=FALSE>>=
y ~ x | z
@
		where \texttt{z} is the conditioning variable.  Sometimes \texttt{y} or \texttt{z} 
		are missing (but the right-hand side \texttt{x} must always be included in a formula).
	\item
		\texttt{data:} A data frame must be given in which the variables mentioned in
		the formula can be found.  Variables not found there will be looked for in the 
		enclosing environment.  Sometimes we will take advantage of this to avoid creating
		a temporary data frame just to make a quick plot, but generally it is best to have
		all the information inside a data frame.
\end{itemize}

\subsection{Patterns and Deviations from Patterns}
The goal of a statistical plot is to help us \emph{see} 
\begin{itemize}
\item 
potential patterns in the data, and 
\item
deviations from those patterns.  
\end{itemize}

\subsection{Different Plots for Different Kinds of Variables}
Graphical summaries can help us see the \emph{distribution} of a variable 
or the \emph{relationships} between two (or more) variables.  The type of plot
used will depend on the kinds of variables involved. Later, when we do more quantitative 
statistical analysis, we will see that the analysis we use will 
also depend on the kinds of variables involved, so this is an important idea.

\subsection{Side-by-side Plots and Overlays Can Reveal Importance of Additional Factors}
Some plots divide data into groups and either produce a panel for each group (using \verb!|!)
or display each group in a different way (different colors or symbols).  These plots can reveal the 
possible influence of additional variables -- sometimes called covariates.

\subsection{Area = (relative) frequency}

Many plots are based on the key idea that our eyes are good at comparing areas.  Plots 
that use area (e.g., histograms, bar charts, pie charts) should always obey
this principle:
\begin{center}
\large
Area $=$ (relative) frequency
\end{center}
Plots that violate this principle can be deceptive and distort the true nature
of the data.  


\newpage

\section*{Exercises}

In your answers to these questions, include both the plots and the code you used 
to make them as well as any required discussion.  Once you have obtained a basic
plot that satisfies the requirements of the question, feel free to 
use some of the ``bells and whistles" to make the plots even better.


\begin{problem}
	Where do the data in the \dataframe{CPS85} data frame (in the 
	\pkg{mosaic} package) come from?  What are the observational 
	units?  How many are there?
\end{problem}

\begin{solution}
<<>>=
require(mosaic)
help(CPS85)
# or alternately:
?CPS85
#to find the number of cases:
dim(CPS85)
#or
nrow(CPS85)
@
The CPS85 data comes from the Current Population Survey, which collects data on the US population between US Census years.  These data are from 1985. The cases in this dataset are the individual persons surveyed.  There are 534 cases (individual people) included in the dataset.
\end{solution}

\begin{problem}
	Choose a quantitative variable that interests you in the \dataframe{CPS85}
	data set.  Make an appropriate plot and comment on what you see.
\end{problem}

\begin{solution}
<<>>=
#an example:
gf_histogram( ~ age , data=CPS85)
@
The CPS85 respondents range in age from under 20 to nearly 70 years old.  The distribution of ages of respondents is unimodal, but not symmetric -- there is a wider spread of ages at the high end of the distribution (in the right tail) than at the left. 
\end{solution}

\begin{problem}
	Choose a categorical variable that interests you in the \dataframe{CPS85}
	data set.  Make an appropriate plot and comment on what you see.
\end{problem}

\begin{solution}
<<>>=
#an example:
gf_bar( ~ married , data=CPS85)
@
There were nearly twice as many married people as single people included in the 1985 CPS. 
\end{solution}


\begin{problem}
	Create a plot that displays two or more variables from the 
	\dataframe{CPS85} data.  At least one should be quantitative 
	and at least one should be categorical.
	Comment on what you can learn from your plot.
\end{problem}

\begin{solution}
<<>>=
#a simple example:
gf_density(~ age , fill=~married , data=CPS85)
@
The single CPS85 respondents were mostly younger than the married ones, with single respondents over 50 making up a very small proportion of the dataset. 
\end{solution}

\begin{problem}
	Where do the data in the \dataframe{mpg} data frame (in the 
	\pkg{ggplot2} package) come from?  What are the observational 
	units?  How many are there?
\end{problem}

\begin{solution}
<<>>=
data(mpg)
#or
?mpg
#or
help(mpg)
#to get the number of units:
#use information above, or
nrow(mpg)
#or
dim(mpg)
@
The mpg dataset contains information on fuel economy of several models of cars (car model years 1999 and 2008). The data were collected by the EPA, and are available on the web site \url{http://fueleconomy.gov}.  The cases are car types (a particular model, from a particular year).  There are 234 cases in the data set.
\end{solution}

\begin{problem}
	Choose a quantitative variable that interests you in the \dataframe{mpg}
	data set.  Make an appropriate plot and comment on what you see.
\end{problem}
\begin{solution}
<<>>=
gf_histogram(~ cty , data=mpg) %>%
  gf_labs(x="Miles per Gallon (city)")
@
Most car models in the dataset got between about 15-20 miles per gallon in the city, and although the distribution of city fuel economy was slightly right-skewed, only a few models got better than 30 miles per gallon. 
\end{solution}

\begin{problem}
	Choose a categorical variable that interests you in the \dataframe{mpg}
	data set.  Make an appropriate plot and comment on what you see.
\end{problem}
\begin{solution}
<<>>=
#an example:
gf_bar(~ class , data=mpg) %>%
  gf_labs(x="Car Type", y='Number of Observations')
@
SUV is the most common car type in the dataset, although pickups, compact cars, subcompact cars, and mid-size cars are also well-represented.  There are relatively few minivans and even fewer 2-seaters in the dataset.
\end{solution}

\begin{problem}
	Create a plot that displays two or more variables from the 
	\dataframe{mpg} data.  At least one should be quantitative 
	and at least one should be categorical.
	Comment on what you can learn from your plot.
\end{problem}

\begin{solution}
<<>>=
#an example:
gf_histogram(~ hwy | class , data=mpg) %>%
  gf_labs(x="Miles per Gallon (highway)",
          title="Highway fuel economy by car type")
@
Larger types of vehicles (like pickups, SUVs, and mini-vans) generally have lower fuel economy than smaller ones (like compact, subcompact, and midsize).
\end{solution}


\begin{problem}The file at \url{http://www.calvin.edu/~rpruim/data/Fires.csv}
	is a csv file containing data on wild lands fires in the US over a number of years.
You can load this data one of two ways.
\begin{itemize}
	\item
		Go to the workspace tab, select \tab{Import Data Set}, choose \tab{From Web URL...}
		and follow the instructions.
	\item
		Use the following command in \R:
<<>>=
Fires <- read.csv("http://www.calvin.edu/~rpruim/data/Fires.csv")
@
\end{itemize}
You can also use either of these methods to read from a file rather than from a
web URL, so this is a good way to get your own data into \R.
\begin{enumerate}
	\item
		The source for these data claim that data before a certain year should not be compared
		to data from after that year because the older data were computed a different way and
		are not considered as reliable.  What year is the break point?  Use graphs of the data 
		over time to estimate when something changed.
	\item
		You can trim the data to just the subset you want using \function{filter()}.  For 
		example, to get just the subset of years since 1966, you would use
<<>>=
Fires2 <- Fires %>%
  filter( Year > 1966)
@
		Be sure to use a new name for the subset data frame if you want to keep the original data available.

		Use \function{filter()} to create a data set that contains only the data from the new data regime (based on your answer in the previous problem).
	\item
		Using only the data from this smaller set, how would you describe what is happening with 
		fires over time?
\end{enumerate}
\end{problem}

\begin{solution}

<<>>=
#read in the data
Fires <- read.csv("http://www.calvin.edu/~rpruim/data/Fires.csv")
#get information about the dataset
head(Fires)
#plot number of fires over time
gf_point(Fires ~ Year, data=Fires)
#plot number of acres burned over time
gf_point(Acres ~ Year, data=Fires)
@
There is an abrupt change in the number of fires per year starting in 1983. (There is no such obvious break-point in the data on the number of acres burned, although you might argue that the number of acres burned began to increase in about 1990-95.)

<<>>=
#trim the data, keeping only data after 1982
Fires2 <- Fires %>%
  filter(Year > 1982)
#plot number of fires over time
gf_point(Fires ~ Year, data=Fires2)
#plot number of acres burned over time
gf_point(Acres ~ Year, data=Fires2)
#number of acres burned per fire over time
gf_point(Acres/Fires ~ Year, data=Fires2) %>%
       gf_labs(y="Acres burned per fire")
@

The number of fires per year is relatively constant (excluding unusually low numbers in 1983-84), but the number of acres burned per year has increased over time.  Specifically, the fires have been larger in size (on average) since about 2000.
\end{solution}


\begin{problem}
	Use \R's help system to find out what the \variable{i1} and \variable{i2}
	variables are in the \dataframe{HELPrct} data frame.  Make histograms
	for each variable and comment on what you find out.  How would you describe
	the shape of these distributions?  Do you see any outliers (observations
	that don't seem to fit the pattern of the rest of the data)?  
\end{problem}

\begin{solution}
<<>>=
require(mosaic) #only if you have not yet done it this session!
?HELPrct
@
i1 is the average number of drinks consumed per day over the past 30 days, in standard units.  i2 is the maxium number of drinks per day (measured in the same way).  

<<>>=
gf_histogram(~ i1, data=HELPrct)
gf_histogram(~ i2, data=HELPrct)
@
The distributions of both i1 and i2 are heavily right-skewed. There are few observations of very heavy drinking (greater than about 75 for i1, or 100 for i2), but they are not necessarily obvious outliers (they fit the right-skewed pattern of the overall dataset).
\end{solution}

\begin{problem}
	Compare the distributions of \variable{i1} and \variable{i2} among men
	and women.
\end{problem}
\begin{solution}
<<>>=
gf_density( ~i1, fill=~sex, data=HELPrct )
gf_density( ~i2, fill=~sex, data=HELPrct )
@
Overall, the distribution for males is more right-skewed in both cases, indicating a greater proportion of males than females who drink more heavily.  The extreme right tail of the i1 (average consumption) distribution extends much further toward high values for males, again indicating more males than females with extremely high consumption.  Both female distributions also have a small second peak in density at higher consumption levels, perhaps indicating a subset of women who are consistently heavier drinkers. This bimodality is especially apparent in the i1 (average drinks per day) data.  
\end{solution}

\begin{problem}
	Compare the distributions of \variable{i1} and \variable{i2} among 
	the three \variable{substance} groups.
\end{problem}
\begin{solution}
<<>>=
gf_density( ~i1, fill=~substance, data=HELPrct )
gf_density( ~i2, fill=~substance, data=HELPrct )
@
<<>>=
gf_density( ~i1|sex, fill=~substance, data=HELPrct )
gf_density( ~i2|sex, fill=~substance, data=HELPrct )
@
Alcohol use is heavier among people whose primary substance of abuse is alcohol, whether we are considering i1 (average use) or i2 (maximum use). Among people whose primary drug of abuse is heroin or cocaine, the distribution of alcohol use among cocaine users is more right-skewed than among heroin users, suggesting that heavier alcohol consumption is more common in combination with cocaine than with heroin.  The observed patterns are relatively similar for males and females.
\end{solution}

\begin{problem}
	The \dataframe{SnowGR} contains historical data on snowfall in Grand Rapids, MI.
	The snowfall totals for November and December 2014 were 31 inches and 1 inch, respectively.
	\begin{enumerate}
		\item
			Create histograms of November and December snowfall totals.  How unusual were the snowfall totals we had in 2014?
		\item
			If there is very little snow in December, should we expect to have unusually much
			or little snow in February?  Make a scatter plot comparing December and February
			historic snowfall totals and comment on what you see there.
	\end{enumerate}
\end{problem}

\begin{solution}
<<>>=
gf_histogram(~Nov, data=SnowGR)
gf_histogram(~Dec, data=SnowGR)
@
November and December 2014 were both very unusual in terms of snowfall. 31 inches was a record high snowfall
total for November.  For December, tallies as low as or lower than 1 inch have been recorded before 2014, 
but were rare.

<<>>=
gf_point(Feb ~ Jan, data=SnowGR)
gf_point(Feb ~ Jan, data=SnowGR)
@
There is no clear relationship between December snowfall and February snowfall.  
Sometimes little snow falls in February after minimal snow in December, but sometimes
there is plenty of February snow despite little snow in December.  (So February 2015 might
yet be snowy!)
\end{solution}
\shipoutProblems

\ifsolutions
\ifsolutionslocal
\newpage
\section*{Solutions}
\shipoutSolutions
\fi
\fi
