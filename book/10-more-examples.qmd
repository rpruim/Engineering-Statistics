
# More Examples {#sec-more-examples}

```{r }
#| label: setup-transformations
#| include: false
library(Devore7)
library(Hmisc)
library(mosaic)
library(mosaicCalc)
library(tidyr)
library(deltaMethod)
library(fastR2)
library(car)
theme_set(theme_bw())
```


## Heat Exchanger Example {#sec-hxer}

In this section we discuss several parts of the statistical
analysis of a laboratory experiment involving a heat exchanger.

### Apparatus and Measurements

@fig-hxer shows a diagram illustrating the 
heat exchanger.  Fluids of different temperatures flow in the annulus 
($\dot{m}_{3}$) and in the inner tube ($\dot{m}_{1}$).
The entire apparatus is insulated, 
so we expect little or no heat to be exchanged with the surroundings.

![Heat exchanger with statepoints.](images/HXerFig.png){#fig-hxer height="4.0in"}


Mass flow rates ($\dot{m}$) are controlled via valves.
Two mass flow rates ($\dot{m}_{1}$ and $\dot{m}_{3}$)
are measured by rotameters.^[See 
<http://www.omega.com/prodinfo/rotameters.html>
for an introduction.]
Temperatures ($T_{1}$--$T_{4}$) are measured by thermocouples.^[See 
<http://www.omega.com/techref/themointro.html> for an introduction.]


<!-- ## Observations -->

Each observation consists of four temperature measurements 
and two mass flow rate measurements. 
Here is an example data set with one set of measurements at each of 6
experimental conditions:
<!-- %<<include = FALSE>>= -->
<!-- %HeatX <- data.frame( -->
<!-- %  trial = 1:6, -->
<!-- %  T.cold.in = c(14.3, 14.1, 14.1, 14.2, 14.1, 14.1), -->
<!-- %  T.cold.out = c(18.6, 18.7, 19.4, 18.4, 17.4, 16.9), -->
<!-- %  # T.hot.in = c(38.2, 35.9, 35.9, 35.8, 35.7, 35.8), -->
<!-- %  T.hot.in = c(38.2, 35.9, 35.9, 35.8, 35.7, 35.8), -->
<!-- %  T.hot.out = c(33.9, 32.8, 33.4, 31.8, 30.9, 30.4), -->
<!-- %  m.cold = c(10, 7.5, 5, 5, 7.5, 10), -->
<!-- %  m.hot = c(10, 10, 10, 5, 5, 5) -->
<!-- %)   -->
<!-- %@ -->

```{r fig.height = 2.25}
library(fastR2)
HeatX   
gf_point(m.hot ~ m.cold, data = HeatX, main = "Experimental Configurations", size = 3)
```


<!-- % Note: \function{read.csv()} can read data from a file as well.  If you are using the server -->
<!-- % version of \RStudio\ you first need to upload your CSV file to the server.  Look in the \tab{Files}  -->
<!-- % pane for the upload button to upload your own data. -->

### Standardizing Units

The recorded flow rates are in L/min.  We will convert them to L/sec and use seconds as
our standard unit of time throughout the analyses.
```{r tidy = FALSE}
HeatX <- HeatX |>
  mutate(
    m.hot = m.hot / 60,
    m.cold = m.cold / 60
  )
```


We could also convert temperatures to degrees Kelvin, but since temperatures only appear 
as differences between two temperatures in the expression used here, we can leave them
in degrees Celsius.


<!-- ### Notation -->

Table @tbl-hxer-definitions contains notation and definitions of important quantities
involved in the heat exchanger experiment.

| Symbol           |   Definition                 | Units                       | Estimate                       |
|------------------|------------------------------|-----------------------------|--------------------------------|
| $\dot{Q}$        | heat transfer rate           | $\mathrm{W}$                |                                |
| $\dot{m}$        | mass flow rate               | $\mathrm{kg}/\mathrm{s}$    |                                |
| $C_{p}$          | specific heat                | $\mathrm{kJ}/(\mathrm{kg}\cdot\mathrm{K})$ | $4.18 \pm 0.1$  |
| $T$              | temperature                  | $\mathrm{K}$                |                                |
| $D$              | diameter of inner tube       | $\mathrm{m}$                | $0.0143 \pm 0.0004$ m          |
|                  | || ($9/16 \pm 1/64$ inches)  |                             |                                |
| $L$              | length of the heat exchanger | $\mathrm{m}$                |  $1.626 \pm 0.006$             |
|                  |                              |                             |  ($64 \pm 1/4$ inches)         |
| $A$              | surface area of the inner tube ($\pi D L$) | m$^{2}$       |                                |
| $U$              | heat transfer coefficient    |$\mathrm{W}/(\mathrm{m}^{2} \cdot \mathrm{K})$ |              |
| $h$		           | convective heat transfer coefficient ($\approx 2 U$) | $\mathrm{W}/(\mathrm{m}^2\cdot \mathrm{K}$) | |
| $\Delta T_{lm}$  | logarithmic mean temperature difference | $\mathrm{K}$     |                                |
| $Nu_{D}$         | Nusselt number based on $D$  | --                          |                                |
| $Re_{D}$         | Reynolds number based on $D$ | --                          |                                |
| $Pr$             | Prandtl number               | --                          |                                |
| $\mu$            | dynamic viscosity            | $\mathrm{kg}/(\mathrm{m} \cdot \mathrm{s})$ | $0.00102 \pm 0.00001$ |
| $k$              | water thermal conductivity   | $\mathrm{W}/(\mathrm{m} \cdot \mathrm{K})$  | $0.598 \pm 0.004$     |

: Notation for quantities involved in the heat exchanger experiment.  Note, some of the physical "constants" are actually temperature dependent.   In these cases, a value has been chosen that reflects the temperature range  (approx. 15--35 degrees C) seen in the data. {#tbl-hxer-definitions}




<!-- \iffalse -->
<!-- \section{Experimental plan} -->

<!-- One possible experimental plan is to take data at -->
<!-- four~(4) values of $\dot{m_{1}}$ and two~(2) values of $\dot{m}_{3}$, -->
<!-- for a total of 8 observations. -->
<!-- Repeated observations could be obtained at one combination of  -->
<!-- $\dot{m}_{1}$ and $\dot{m}_{3}$. -->
<!-- \fi -->


### Calculating the heat transfer, $\dot Q$

The amount of heat exchanged between the hot and cold water can be determined
from the temperature change and the mass flow rate as follows:

$$
    \dot{Q}_{1} = \dot{m}_{1} C_{p} (T_{2} - T_{1})
$$ {#eq-hxer1}

$$
    \dot{Q}_{3} = \dot{m}_{3} C_{p} (T_{4} - T_{3})
$$ {#eq-hxer2}

We can estimate the values of $\dot{Q}$ from our data by direct calculation:
```{r tidy = FALSE}
C_p <- 4.18
HeatX2 <- HeatX |>
  mutate(
    Q.cold = m.cold * C_p * (T.cold.out - T.cold.in),
    Q.hot  = m.hot  * C_p * (T.hot.out  - T.hot.in),
    Q.env  = Q.cold + Q.hot
  )
HeatX2
```


### Estimating heat exchanged with environment
If no heat were exchanged with the environment and all measurements were without error,
then our two estimates of $\dot Q$ would sum to 0.  (Heat lost to one fluid is gained by the 
other.)  

Assuming any loss to (or gain from) the environment is essentially constant for
the apparatus over the experimental conditions analysed, we can use our 6
observations to estimate the amount of heat exchanged with the environment:
```{r }
df_stats( ~ Q.env, data = HeatX2)
gf_point( "" ~ Q.env, data = HeatX2, alpha = .6, cex = 3, 
          position = "jitter", width = 0, height = 0.05)
```

From this we can compute either a p-value for the hypothesis test that the mean 
difference in heat change is 0 or create a confidence interval for the mean difference
in heat change.
The information above is enough to do this "by hand" using the standard error 
formula $SE = \frac{s}{\sqrt{n}}$ and a t-distribution with $n-1 = 5$ degrees of freedom.

```{r tidy = FALSE}
xbar <- 0.08999
SE = 0.08274 /sqrt(6); SE
xbar + c(-1,1) * qt(0.975, df = 5) * SE       # 95% CI
t <- (0.08999 - 0) / SE; t
2 * pt( -abs(t), df = 5 )                     # p-value
```


Or we can let R do all the computations for us:

<!-- %qplot( Q.env, " ", data = HeatX2,  -->
<!-- %       geom = "point", size = I(6), alpha = I(.5),  -->
<!-- %       position = position_jitter(width = 0, height = .1)) -->

```{r fig.height = 2}
t.test( ~ Q.env, data = HeatX2)
```

In our example data, there is modest evidence for exchange with the environment, but
the estimated amount of heat gained from the environment is not very precisely 
estimated.  But even at the highest end of the confidence interval, the heat exchanged 
with the environment is an order of magnitude smaller than the heat exchanged 
within in the apparatus.

Notes:

::: {.enumerate}

#.  The fact that heat is gained to the system suggests that the cold water was in the
outer pipe and hot water in the inner pipe.
#.  This analysis assumes that the amount of heat gained/lost is constant over 
the different set-ups.  From this small data set, there is not clear evidence 
of some other relationship between heat exchanged with the environment
and the experimental set up:

    ```{r fig.height = 2.5, fig.width = 6}
    gf_point(Q.env ~ m.cold, data = HeatX2, 
             color = ~ paste("m.hot =", round(m.hot,2))) |>
      gf_labs(color = "")
      
    ```

#.  The t-test and interval are based on the assumption that the distribution
of deviations between the measured environment heat exchange and the actual
is normally distributed.  The data set is too small to provide much evidence
upon which to judge whether this is a reasonable assumption.  The largest value is 
quite a bit larger than the rest, but even if we remove that observation, our 
conclusions don't change dramatically:

    ```{r }
    t.test( ~ Q.env, data = subset(HeatX2, Q.env < max(Q.env)) )
    ```

::: 
<!-- end enumerate -->


Overall, we conclude that there is likely some heat exchanged with the environment, but 
the amount of heat exchange with the environment
appears to be at most a small factor in this situation.

### Estimating heat transfer between hot and cold water, $\dot{Q}$

Estimating $\dot{Q}$ with uncertainty is not possible from this data alone since 
$\dot{Q}$ is not measured directly, and we have only one measurement for each experimental
condition (so no way to look at how variable such measurements are without additional information.
Furthermore, the design doesn't provide a method for estimating the 
uncertainty in $\dot{m}$ and $T$.

If, however, there are external estimates of the uncertainties for temperature
and flow rate, and if we can assume these uncertainties are approximately
independent, then we can use propagation of uncertainty to estimate the
uncertainty in our estimates for heat exchanged.  Such uncertainties might come 
from specifications of the equipment used or be based on past experience of the
researcher.

For example, suppose that the uncertainties in temperature and flow rate 
measurements  are approximately constant (over the range of temperatures involved): 
$u_T$, and  $u_{\dot{m}}$.  Then the uncertainty in the difference between two
independent temperatures is 
$\sqrt{ u_T^2 + u_T^2 } = \sqrt{2} \cdot u_T$, and we can estimate the uncertainty in
$\dot Q$ using the delta method.

::: {.itemize}

* Let $\dot{Q}(\dot{m}, \Delta T) = C_p \dot{m} \Delta T$
* $\displaystyle \Partial{\dot{Q}}{\dot m} = C_p \Delta T$ and 
$\displaystyle \Partial{\dot{Q}}{\Delta T} = C_p \dot{m}$, so
* $\displaystyle u_{\dot Q} \approx C_p \sqrt{ (\Delta T)^2 u^2_{\dot m}  + \dot{m}^2 u_{\Delta T}^2 }$
::: 

<!-- end itemize -->


If we estimate the uncertainty in measured temperatures
to be $1$ degree C and the uncertainty in flow rate to be $0.5$ liters per
minute (i.e., `r 0.5/60` L/sec), then we can compute the uncertainties in 
the $\dot{Q}$ values as follows
```{r tidy = FALSE}
HeatX2<- HeatX2 |>
  mutate(
    u.Q.cold = C_p *sqrt( (T.cold.out - T.cold.in)^2 * (0.5/60)^2  + m.cold^2 * 2),  
    u.Q.hot =  C_p *sqrt( (T.hot.out  - T.hot.in)^2  * (0.5/60)^2  +  m.hot^2 * 2) 
  ) 
HeatX2
```

Note: We are using the fact that $u_{\Delta T} = \sqrt{2} u_T$.

We can also use `deltaMethod()` in the **`car`** package to do this
arithmetic for us.  In fact, `deltaMethod()` can even handle cases
where the estimates are not independent.  To do it's job,
`deltaMethod()` requires

::: {.itemize}

* A named vector of estimates,

```{r }
estimates <- HeatX[1, 2:7] |> unlist()  # unlist() turns the data frame into a vector
estimates
```

* An expression for the derived quantity as a quoted string 
	(it will do the derivatives for us!),
	
```{r }
exprforQ <- "(T.cold.out - T.cold.in) * C_p * m.cold"
```

* A variance-covariance matrix.  In the simple case where things are
	independent, this is just a matrix with the squared uncertainties on the
	diagonal and 0 everywhere else.
	
```{r }
vc <- diag( c(1,1,1,1,.5/60,.5/60)^2)
vc
```

::: 
<!-- end itemize -->

Let's see how it compares to the (first row of the) results above:
```{r }
library(car)
deltaMethod(estimates, exprforQ, vc)
```



The **`deltaMethod`** package adds additional interfaces for `deltaMethod()` to 
make this even easier.

```{r }
library(deltaMethod)
deltaMethod(HeatX, exprforQ, 
  uncertainties = c(T.cold.in = 1.0, T.cold.out = 1.0, m.cold = 0.5 / 60))
```


#### Dealing with uncertainties that are not constant

Sometimes the uncertainties of a given variable are different at different values.
In that case, we can put the uncertainties into the data frame.  For the current 
example, this is just extra work, but we include it here to show how it works.

```{r tidy = FALSE}
HeatX3 <- HeatX |>
  mutate(
    u.cold.in = 1, u.cold.out = 1, u.hot.in = 1, u.hot.out = 1, 
    u.m.cold = 0.5/60, u.m.hot = 0.5/60
  )
HeatX3
deltaMethod(HeatX3,
  exprforQ, 
  estimates     = c("T.cold.in", "T.cold.out", "m.cold"),    # columns with estimates
  uncertainties = c("u.cold.in", "u.cold.out", "u.m.cold"))  # and uncertainties
```

Although our uncertainties are the same in each row, this method allows for uncertainties 
to be specified separately for each row of the data.

### Does the uncertainty in $C_p$ matter?

In the analysis above, we treated $C_p$ as a constant (with arbitrary precision).  
But this number is also known experimentally and has an uncertainty associated with it.
Do our results change if we include this uncertainty in our calculations?

```{r tidy = FALSE}
deltaMethod( HeatX |> mutate(C_p = 4.18), exprforQ,      # add in a column for C_p
  uncertainties = c(T.cold.in = 1.0, T.cold.out = 1.0, m.cold = 0.5/60, C_p = 0.1))
```


Comparing these results to the results above we see that the uncertainty
increases, but only by amounts that are barely visible (a few parts per
1,000 -- not enough to affect how we report the uncertainty given our rules
for reporting digits).  This has no meaningful impact on our analysis.

We can often simplify propagation of uncertainty calculations by identifying which 
components of the uncertainty are driving the size of the overall uncertainty.  In this case, 
the imprecision in the estimated value of $C_p$ is unimportant.  If we want to improve our
uncertainty, we must improve our measurements of temperature and/or flow rate.

### Using relative uncertainty

Recall that for products, there is a Pythagorean relationship for relative uncertainties.

$$
\frac{u_{\dot Q}}{\dot Q} \approx 
\sqrt{ 
(\frac{u_{\dot m}}{\dot{m}})^2
+
(\frac{u_{\Delta T}}{\Delta T})^2
+
(\frac{u_{C_p}}{C_p})^2
}
$$
This is useful in determining what uncertainties contribute most to the overall uncertainty.
For example, using the values in the first row of the data set.

::: {.itemize}

* $\displaystyle \frac{u_{\dot{m}}}{\dot{m}} = \frac{0.5/60}{10/60} = `r 0.5/10`$
* $\displaystyle \frac{u_{\Delta T}}{\Delta T} = \frac{\sqrt{2}}{4.5} = `r sqrt(2)/4.5`$
* $\displaystyle \frac{u_{C_p}}{C_p} = \frac{0.1}{4.18} = `r 0.1/4.18`$
::: 

<!-- end itemize -->

From this we can see that it is the imprecise temperature measurements that are our biggest
problem.  Even if we eliminated the other uncertainties, we would still have a relative uncertainty
of over $30$%.   The details vary a bit from row to row, but the uncertainty in temperature 
is our biggest obstacle.  In addition to increasing the precision of our temperature sensors, we could 
also potentially improve things by designing a heat exchanger with more dramatic changes in 
temperature.

Suppose, for example, we could estimate temperature with an uncertainty of 0.1 degrees (ten times 
better than we have been assuming).  Then our uncertainties for $\dot{Q}$ would change pretty
dramatically.

```{r }
HeatX |>
  mutate(C_p = 4.18) |>  # add in a column for C_p
  deltaMethod(
    exprforQ,      
    uncertainties = c(T.cold.in = 0.1, T.cold.out = 0.1, m.cold = 0.5/60, C_p = 0.1))
```


But if we improve the uncertainty in the mass flow rate by a factor of 10, it has only a 
modest impact on our uncertainty for $\dot{Q}$.

```{r }
HeatX |>
  mutate(C_p = 4.18) |>  # add in a column for C_p
  deltaMethod(
    exprforQ,      
    uncertainties = c(T.cold.in = 1.0, T.cold.out = 1.0, m.cold = 0.5/600, C_p = 0.1))
```


### Estimating the heat transfer coefficient, $U$

Next, we estimate a heat transfer coefficient ($U$) for both streams,

$$
U = \frac{\dot{Q}}{A \Delta T_{lm}},
$$

where 

$$
\Delta T_{lm} \equiv \frac{(T_{1} - T_{4}) - (T_{2} - T_{3})}{\log\left( \frac{T_{1} - T_{4}}{T_{2} - T_{3}} \right)}.
$$

We can apply the same ideas to estimate the uncertainty in $U$.  This time,
working it out by hand would be considerably more tedious because of the number
of variables involved and the form of the expression to be differentiated.
Fortunately, R is happy to take care of those details if we just specify the
information needed.

```{r tidy = FALSE}
exprforU <- paste("C_p * m.cold * (T.cold.out - T.cold.in) /",
                  "( pi * D *  L  * ((T.cold.out - T.hot.in) - (T.cold.in - T.hot.out)) /",
                  " log ( (T.cold.out - T.hot.in) / (T.cold.in - T.hot.out) ) )")
HeatX4 <- HeatX |>
  mutate(D = 0.0143, L = 1.626, C_p = 4.18)
HeatX4
deltaMethod(
  HeatX4, 
  exprforU, 
  uncertainties = c(
    T.cold.in = 1.0, T.cold.out = 1.0, m.cold = 0.5/60, 
    T.hot.in = 1.0, T.hot.out = 1.0, m.hot = 0.5/60, 
    C_p = 0.1, D = 0.0004, L = 0.0006),
  constants = list(pi = pi)
)
```


Note the use of the `constants` argument here to specify the value of `pi`.  
We could also have specified $C_p$ this way if we decided to ignore the uncertainty
in that value.  But since it is no harder to include that uncertainty, we included it.


### Estimating the Nusselt number correlation,  $a$

Finally, we can estimate
the parameter $a$ in a Nusselt number correlation
for turbulent flow ($Re_{D} > 2300$):

$$
    a = \frac{Nu_D}{Re_{D}^{0.8} Pr^{1/3}},
$$

where

$$
	Nu_{D} = \frac{h D}{k} \approx \frac{ 2 U D}{k}, 
$$

$$
    Re_{D} = \frac{4 \dot{m}}{\pi D \mu},
$$

and

$$
    Pr = \frac{\mu C_{p}}{k}.
$$

The uncertainty in the estimates for $a$ can be estimated in a similar manner.
For that purpose, we assume that the exponents on $Re_{D}$ and $Pr$
(0.8 and 1/3, respectively)
are constant.
The values of $C_{p}$, $k$, and $\mu$ are given in @tbl-hxer-definitions.

To complete our uncertainty calculation we must

::: {.enumerate}

#.  Create an expression for the quantity we are interested in (as a quoted string).
#.  Create a data frame that has all of the components of this expression
		that have uncertainties.
#.  Create a named vector of uncertainties.  The names should correspond 
		to the variables names in the data frame, the values are the uncertainties.
		(Alternatively, the uncertainties can be put inside the data frame and 
		the arguments `estimates` and `uncertainties` can be 
		used to specify which columns are the estimates and which are the
		corresponding uncertainties.)
#.  Create a list that contains the value of any constants (or values for which
		we are ignoring that there is uncertainty because the uncertainty is so 
		small that it doesn't affect the analysis).
::: 
<!-- end enumerate -->


This is left as an exercise for you.


## Standard Errors in `fitdistr()` output

We had not yet learned about uncertainty and standard errors when we learned about 
`fitdistr()`, but the output from the function includes an estimated standard
error.
```{r }
library(fastR2)
fitdistr(Jordan8687$points, "normal")
```

The parenthesized numbers are the estimated standard errors associated with each
parameter estimate.
In this case, it is easy to compute the standard error for the mean ourselves
using $SE = s / \sqrt{n}$.
```{r }
sd( ~ points, data = Jordan8687) / sqrt(82)
```



## $R^2$ {#sec-r-squared}

::: {.center}

*Note: the methods in this section assume a linear model with an intercept term.*
::: 
<!-- end center -->


Recall that linear models are fit by minimizing the sum of the squares of the 
residuals:[^ $RSS$ stands for Residual Sum of Squares; $SSE$ stands for Error Sum of Squares.]
$$
RSS = SSE = \sum_{i = 1}^{n} ( y_i - \hat y)^2
$$
This expression reminds us of^[$SST$ stands for Total Sum of Squares.]
$$
SST = \sum_{i = 1}^{n} ( y_i - \mean y)^2 \;,
$$
the numerator of the variance of $y$.  $SST$ is a measure
of the total variation in the response variable.

A little algebra shows that^[SSM stands for Model Sum of Squares.]
$$
SSM = SST - SSE = 
\sum_{i = 1}^{n} ( \hat y - \mean y)^2 \;,
$$
We can now define $R^2$ by
$$
R^2 = \frac{SSM}{SST}  = \frac{SSM}{ SSM + SSE }
= \mbox{proportion of variability in the response explained by the model.}
$$
$R^2$ is always between 0 and 1 and is reported in the summary output
for linear models.  It is the square of the correlation coefficient
that we saw earlier.
```{r }
summary(lm(sat ~ expend, data = SAT))  # how does the average SAT score depend on money spent?
```

Notice that $R^2 < 15$% and that the coefficient on `expend` is negative -- indicating 
that spending more is associated with *worse* scores on the SAT.

One reason for this is that in some states most college bound students take the SAT, but in 
other states, the ACT is more common so the pool of students taking the SAT is stronger.
If we add `frac` -- the fraction of students in a given state who took the SAT.
```{r }
summary(lm(sat ~ expend + frac, data = SAT))
```

Notice how much larger $R^2$ is now, and that the sign of the coefficient on `expend`
is now positive -- as we would have expected.

It is important to note that adding in the additional variable `frac` gives a very
different impression of the effect of `expend` on `sat`.  Most of our examples 
have dealt with one response to one predictor, but in many situations, this is too simplistic and
the inclusion of multiple predictors in the model is required to understand their impact on 
the response.


## Exercises

::: {.problem #exr-uncertainty-nusselt}

Give an estimate with uncertainty for the
Nusselt number correlation using the data in `HeatX` used
in this chapter.
::: 
<!-- end problem -->
