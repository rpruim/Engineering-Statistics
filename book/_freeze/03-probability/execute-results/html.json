{
  "hash": "6fbfa18db5ca0e7fa4e0a5baa7fb178e",
  "result": {
    "markdown": "---\neditor: \n  markdown: \n    wrap: 72\n---\n\n\n# Probability\n\n\n\n\n\n\n\n## Key Definitions and Ideas\n\nThe terms below will help us talk about randomness and probability.\n\n<!-- begin description -->\n\n-   **random process** A repeatable process that has multiple\n    unpredictable potential outcomes.\n\n    Although we sometimes use language that suggests that a *particular\n    result* is random, it is really the *process* that is random, not\n    its results.\n\n-   **outcome** A potential result of a random process.\n\n-   **sample space** The set of all possible potential outcomes of a\n    random process.\n\n-   **event** A subset of the sample space.\\\n    That is, a set of outcomes (possibly all or none of the outcomes).\n\n    Statisticians often use capital letters from the beginning of the\n    alphabet for events.\n\n-   **trial** One repetition of a random process.\n\n-   **mutually exclusive** events. Events that cannot happen on the same\n    trial.\n\n-   **probability** A numerical value between 0 and 1 assigned to an\n    event to indicate how often the event occurs (in the long run).\n\n-   **random variable** A random variable is a variable whose value is a\n    numerical outcome of a random process.\n\n-   **probability distribution** The distribution of a random variable.\n    (Remember that a distribution describes *what values?* and *with\n    what freqency?*)\n\n<!-- end description -->\n\n### Examples of random variables\n\nBelow are some random processes that result in a number.\n\n-   Roll a die and record the **number**.\n-   Roll two dice and record the **sum**.\n-   Flip 100 coins and count the **number of heads**.\n-   Sample 1000 people and **count** how many approve of the job the\n    president is doing.\n\nNote: Statisticians usually use capital letters (often from the end of\nthe alphabet) for random variables, like this:\n\n::: {.center}\nLet $X$ be the number of heads in 10 flips of a fair coin. What is\n$\\Prob(X = 5)$?\n:::\n\nAs an example of a probability distribution, we can first consider a\n*discrete* random variable. Most of the examples of random variables\ngiven above are discrete. In other words, the values they can take on\ncome from a set containing a finite number of possible values. For\nexample, if you roll a 6-sided die and record the number that comes up,\nthere are only size possible outcomes, which are equally likely: the\nintegers 1, 2, 3, 4, 5 and 6. For discrete random variables, the\nprobability distribution shows all the possible values on the x-axis,\nand the likelihood of observing each of those values on the y-axis.\nSince there are a finite number of possible values that can be observed,\nthese likelihoods are actually the *probabilities* of observing each\noutcome, and the sum of all the probabilities must be 1 (see\n@sec-theoretical-prob for details). For our example, where we rolled a\ndie and recorded the value:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](03-probability_files/figure-html/discrete-pmf-1.png){width=624}\n:::\n:::\n\n\nThings are a bit more complicated for *continuous* random variables (the\nones that can take on any numerical value). Here, there sample space\n(the set of possible distinct values the random variable can take on) is\ninfinite. One consequence of this fact is that the interpretation of the\ny-axis values of the probability distribution changes. The y-axis will\nstill indicate the relative likelihood of observing any given value of\nthe random variable. However, here the random variable can take on an\ninfinite number of possible values. In this case, we can't interpret the\ny-axis values as probabilities. They y axis units are called\n\"Likelihood\" or \"Density\", and they indicate the relative frequency of\neach outcome. For a densityplot, Density is scaled such that the\nintegral over all possible x-values (the area under the curve) is 1.\n(For a histogram, Density is scaled so that the total area of all the\nboxes added together is 1.) We can think of the histograms and density\nplots we have been creating using continuous variables from R datasets\nas attempts to use data to approximate the distributions of random\nvariables. For example, we might consider the growth of flower petals of\nthe iris *Iris setosa* as a random process, and let `X` be a random\nvariable that is the length of each iris petal. We could plot a\nhistogram to approximate the distribution of `X` using the variable\n`Petal.Length` from the `iris` data (from the **`datasets`** package in\nbase R).\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](03-probability_files/figure-html/cont-pdf-1.png){width=432}\n:::\n:::\n\n{{< pagebreak >}}\n\n\n\n## Calculating Probabilities Empirically\n\nWe would like to calculate the probability of an event $A$, denoted\n$\\Prob(A)$.\n\nIn the next section, we will see how to calculate probabilities based on\nthe Axioms of probability, and logic. But first, we will consider ways\nto make the calculations empirically -- based on observing many\nrepetitions of a random process (in real life or in a computer\nsimulation) and observing how often an event of interest occurs.\n\nRandom processes are repeatable, so practically, we can calculate\nempirical probabilities by simply repeating the process over and over\nand keeping track of how often the event $A$ occurs. For example, we\ncould flip a coin 10,000 times and see what fraction are heads.[^1]\n\n[^1]: This has actually been done a couple of times in history,\n    including once by mathematician John Kerrich while he was a prisoner\n    of war during World War II.\n\n$$\n\\mbox{Empirical Probability} =\n\\frac{\\mbox{number of times $A$ occured}}\n{\\mbox{number of times random process was repeated}} \n$$\n\nModern computing provides another way to compute empirical\nprobabilities. If we can simulate our random process on a computer, then\nwe can repeat the process many times very quickly.\n\n::: {.example #exm-5Heads}\n\n**Q.** What is the probability of getting exactly 5 heads if you flip a\nfair coin 10 times? Using our random variable notation, let $X$ be the\nnumber of heads in 10 flips of a fair coin. We want to know\n$\\Prob(X = 5)$.\n\n**A.** The `rflip()` function simulates flipping a coin as many times as\nwe like.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrflip(10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nFlipping 10 coins [ Prob(Heads) = 0.5 ] ...\n\nT T T T H T H T H H\n\nNumber of Heads: 4 [Proportion Heads: 0.4]\n```\n:::\n:::\n\n\nThe `do()` function allows us to execute an R command (\"do\" somthing in\nR) over and over, as many times as we choose. Here, our `rflip()`\ncommand simulates 10 coin-flips. First we'll \"do\" our command three\ntimes and show the results. Then we'll do it 10,000 times and store the\nresults in a variable called `tosses`, so we can create a table and a\nplot showing the empirical distribution.\n\n\n::: {.cell hash='03-probability_cache/html/coin-tosses_09f593aa9238d2d87303b9fb401d0963'}\n\n```{.r .cell-code}\ndo(3) * rflip(10)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"n\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"heads\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tails\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"prop\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"10\",\"2\":\"6\",\"3\":\"4\",\"4\":\"0.6\"},{\"1\":\"10\",\"2\":\"4\",\"3\":\"6\",\"4\":\"0.4\"},{\"1\":\"10\",\"2\":\"6\",\"3\":\"4\",\"4\":\"0.6\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\ndo(10000) * rflip(10) -> tosses\ntally(~ heads, data = tosses, format = \"prop\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nheads\n     0      1      2      3      4      5      6      7      8      9     10 \n0.0008 0.0091 0.0422 0.1254 0.1982 0.2466 0.2114 0.1176 0.0392 0.0088 0.0007 \n```\n:::\n\n```{.r .cell-code}\ngf_histogram( ~ heads, data = tosses, binwidth = 1)\n```\n\n::: {.cell-output-display}\n![](03-probability_files/figure-html/coin-tosses-1.png){width=432}\n:::\n:::\n\n\n\n\nBased on this sample, we would estimate that\n$\\Prob(X = 5) \\approx 0.2466$.\n:::\n\n::: {.example #exm-doublesSims}\n\n**Q.** Use simulations to estimate the probability of rolling doubles\nusing two fair standard dice.\n\n**A.** We can simulate rolling a die with the following code:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n1:6                # the numbers 1 through 6\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1 2 3 4 5 6\n```\n:::\n\n```{.r .cell-code}\nresample(x = 1:6, size = 10)  # ten rolls of a 6-sided die\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 2 1 4 1 1 2 6 2 5 4\n```\n:::\n:::\n\n\nThe first 2 input arguments of `resample()` are `x` (the set of values\nfrom which you want to resample) and `size` (the number of items to\nchoose from `x`). You can also think of `size` as the number of *times*\nto sample from `x`, if you are imagining sampling one item from `x` each\ntime.\n\nIf we do this 10,000 times for each of two dice...\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndie1 <- resample(1:6, 10000)\ndie2 <- resample(1:6, 10000)\n# let's check that things look reasonable\nhead(die1) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 6 2 1 6 6 4\n```\n:::\n\n```{.r .cell-code}\nhead(die2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1 2 4 4 1 2\n```\n:::\n:::\n\n\nThen we can tabulate how often the two numbers matched in one of two\nways:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntally( ~(die1 == die2) )    # NOTE the double == here\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(die1 == die2)\n TRUE FALSE \n 1634  8366 \n```\n:::\n\n```{.r .cell-code}\nprop( ~(die1 == die2) )     # NOTE the double == here\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nprop_TRUE \n   0.1634 \n```\n:::\n:::\n\n\nSo the probability appears to be approximately\n0.1634.\n:::\n\n::: {.example #exm-sum8}\n\n**Q.** Use simulation to estimate the probability of rolling a sum of 8\nwhen rolling two fair six-sided dice.\n\n**A.** We have already generated 10000 random rolls, so let's just reuse\nthem. (Alternatively, we could generate new rolls.)\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns <- die1 + die2 \n# R adds element-wise: \n#   first entry of die1 + first of die2, \n#   second to second, etc.\nprop( ~ (s == 8) )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nprop_TRUE \n   0.1443 \n```\n:::\n:::\n\n\nWe can estimate the probability of any sum the same way.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntally( ~ s )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ns\n   2    3    4    5    6    7    8    9   10   11   12 \n 291  579  810 1067 1382 1625 1443 1102  855  571  275 \n```\n:::\n\n```{.r .cell-code}\ntally( ~ s, format = \"percent\" )   # if we are too lazy to divide by 10000 ourselves\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ns\n    2     3     4     5     6     7     8     9    10    11    12 \n 2.91  5.79  8.10 10.67 13.82 16.25 14.43 11.02  8.55  5.71  2.75 \n```\n:::\n:::\n\n\nHere's a slightly fancier version that puts all the information into a\ndata frame. Note the use of the function `data.frame()` to create the\ndata table:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrolls <- data.frame( first = die1, second = die2, sum = die1 + die2 )\nhead(rolls)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"first\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"second\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"sum\"],\"name\":[3],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"6\",\"2\":\"1\",\"3\":\"7\",\"_rn_\":\"1\"},{\"1\":\"2\",\"2\":\"2\",\"3\":\"4\",\"_rn_\":\"2\"},{\"1\":\"1\",\"2\":\"4\",\"3\":\"5\",\"_rn_\":\"3\"},{\"1\":\"6\",\"2\":\"4\",\"3\":\"10\",\"_rn_\":\"4\"},{\"1\":\"6\",\"2\":\"1\",\"3\":\"7\",\"_rn_\":\"5\"},{\"1\":\"4\",\"2\":\"2\",\"3\":\"6\",\"_rn_\":\"6\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\ntally( ~sum, data = rolls, format = \"proportion\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nsum\n     2      3      4      5      6      7      8      9     10     11     12 \n0.0291 0.0579 0.0810 0.1067 0.1382 0.1625 0.1443 0.1102 0.0855 0.0571 0.0275 \n```\n:::\n\n```{.r .cell-code}\ngf_histogram( ~ sum, data = rolls, binwidth = 1)    # setting width is important for integer data\n```\n\n::: {.cell-output-display}\n![](03-probability_files/figure-html/unnamed-chunk-8-1.png){width=432}\n:::\n:::\n\n:::\n\n## Calculating Probabilities Theoretically {#sec-theoretical-prob}\n\nThe theoretical method combines <!-- begin enumerate -->\n\n1.  Some basic facts about probability (the Probability Axioms and\n    Rules),\n2.  Some assumptions about the particular situation at hand, and\n3.  Mathematical reasoning (arithmetic, algebra, logic, etc.).\n    <!-- end enumerate -->\n\n### The Three Probability Axioms\n\n::: {.boxedText}\nLet $S$ be the sample space and let $A$ and $B$ be events.\n\n1.  Probability is between 0 and 1: $0 \\le \\Prob(A) \\le 1$.\n2.  The probability of the sample space is 1: $\\Prob(S) = 1$.\n3.  Additivity: If $A$ and $B$ are mutually exclusive, then\n    $\\Prob(A \\tor B) = \\Prob(A) + \\Prob(B)$.\n:::\n\n#### Notation Notes {.unnumbered}\n\n$\\Prob(A \\tor B)$ is the probability that either $A$ or $B$ (or both)\noccurs. Often this is written $\\Prob(A \\union B)$. $A \\union B$ is\nusually read \"$A$ union $B$\". The union of two sets is the set that\ncontains all elements of both sets.\n\n$\\Prob(A \\tand B)$ is the probability that *both* $A$ and $B$ occur.\nThis is also written $\\Prob(A \\intersect B)$. $A \\intersect B$ is\nusually read \"$A$ intersect $B$\".\n\nSaying that $A$ and $B$ are mutually exclusive is the same as saying\nthat there are no outcomes in $A\\intersect B$, i.e., that\n$A \\intersect B = \\emptyset$.\n\n### Other Probability Rules\n\nThese rules all follow from the axioms (although we will not necessarily\nprove them all here).\n\n::: {.boxedText}\n\n#### The Addition Rule {.unnumbered}\n\nIf events $A$ and $B$ are mutually exclusive, then\n$\\Prob(A \\tor B) = \\Prob(A) + \\Prob(B)$. That's the additivity axiom. A\nmore general rule holds even when the events are not mutually exclusive:\n$$ \n\\Prob(A \\tor B) = \\Prob(A) + \\Prob(B) - \\Prob(A \\tand B) \\; . \n$$\n\n#### The Complement Rule {.unnumbered}\n\n$$\n\\Prob(\\tnot  A) = 1 - \\Prob(A) \n$$\n\n#### The Equally Likely Rule {.unnumbered}\n\nIf the sample space consists of $n$ equally likely outcomes, then the\nprobability of an event $A$ is given by\n\n$$ \n\\Prob(A) \n= \\frac{ \\mbox{number of outcomes in $A$}}{n}\n= \\frac{ \\card{A} }{\\card{S} }\\; . \n$$\n\n*Warning:* One of the most common mistakes in probability is to apply\nthis rule when the outcomes are not equally likely.\n\n:::\n\n::: {.example #exm-equallyLikley}\n\nHere are several examples where we can (and cannot) use the Equally Likely Rule.\n\na.  Coin Toss: $\\Prob(\\mbox{heads}) = \\frac{1}{2}$ if heads and tails\n    are equally likely.\nb.  Rolling a Die: $\\Prob(\\mbox{even}) = \\frac{3}{6}$ if the die is fair\n    (each of the six numbers equally likely to occur).\nc.  Sum of two Dice: the sum is a number between 2 and 12, but these\n    numbers are NOT equally likely.\n\n    There are 36 equally likely combinations of two dice:\n\n\n    ::: {.cell layout-align=\"center\"}\n    ::: {.cell-output-display}\n    ![](03-probability_files/figure-html/unnamed-chunk-9-1.png){fig-align='center' width=336}\n    :::\n    :::\n\n\n    Let $X$ be the sum of two dice.\n\n    *  $\\Prob(X = 3) = \\frac{2}{36} = \\frac{1}{18}$\n    *  $\\Prob(X = 7) = \\frac{6}{36} = \\frac{1}{6}$\n    *  $\\Prob(\\mbox{doubles}) = \\frac{6}{36} = \\frac{1}{6}$\n\nd.  Punnet Squares\n\n    This example comes from animal or human genetics. Here, we consider a\ngene with two alleles: A is the dominant allele, and a is the recessive\none. Each individual has two copies of every gene, so there are three\npossible combinations of alleles (called \"genotypes\"): AA, Aa, and aa.\nAA and Aa individuals have the dominant A physical characteristic\n(called the \"phenotype\"); aa individuals have the recessive a phenotype.\nImagine that two Aa individuals mate and produce offspring. In this Aa\n$\\times$ Aa cross, if A is the dominant allele, then the probability of\nthe dominant phenotype is $\\frac{3}{4}$, and the probability of the\nrecessive phenotype is $\\frac{1}{4}$ because each of the four possible\ncrossings is equally likely.\n\n:::: {.center}\n\n+:---:+:---:+:---:+\n|     | A   | a   |\n+-----+-----+-----+\n| A   | AA  | Aa  |\n+-----+-----+-----+\n| a   | aA  | aa  |\n+-----+-----+-----+\n\n: A Punnet Square {tbl-colwidths=\"[8,8,8]\" #tbl-punnet}\n\n\n![<http://xkcd.com/634/>](images/date-punnet.png)\n\n::::\n\n:::\n<!-- end example -->\n\n\n{{< pagebreak >}}\n\n\n\n\\section{Conditional Probability}\n\n::: {.example #exm-cond-kids}\n\n**Q.** Suppose a family has two children and one of them is a boy. What\nis the probability that the other is a girl?\n\n**A.**\n<!--  First we introduce some notation.  Let $X$ be a random variable -->\n<!--  that counts the number of girls and let $Y$ be a random variable -->\n<!--  that counts the number of boys (since they have Y chromosomes). -->\n<!--  We'll also  --> \nWe'll make the simplifying assumption that boys\nand girls are equally likely (which is not exactly true). Under that\nassumption, there are four equally likely families: BB, BG, GB, and GG.\nBut only three of these have at least one boy, and we already know our\nfamily has at least one boy, so our sample space is really\n$\\{BB, BG, GB\\}$. Of these, two have a girl as well as a boy. So the\nprobability is $2/3$.\n\nWe illustrate the restricted sample space (3 outcomes in a box) in the \nfigure below. Two of these three outcomes have at least one girl.\n(See @eq-cond-kids.)\n\n$$\n\\mbox{GG} \\ \\ \\  \\fbox{BG \\ \\ \\ GB \\ \\ \\ BB}\n$$ {#eq-cond-kids}\n\nWe can also think of this in a different way. In our original sample\nspace of four equally likely families, \n\n$$\n\\begin{aligned}\n\\evProb{at least one girl} & =  3/4 \\; , \\\\ % \\mbox{ , and } \\\\\n\\evProb{at least one girl \\emph{and} at least one boy} & =  2/4 \\; , \\tand\\\\\n\\frac{2/4}{3/4} & =  2/3 \\; ;\n\\end{aligned}\n$$\n\nso $2/3$ of the time when there is at least one boy, there is also a\ngirl. We will denote this probability as\n$\\Prob(\\mbox{at least one girl} \\mid \\mbox{at least one boy})$. We'll\nread this as \"the probability that there is at least one girl \n*given that* there is at least one boy\".\nSee @fig-VennConditional and @def-condProb.\n:::\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![A Venn diagram illustrating the definition of conditional probability. $\\Prob(A \\mid B)$ is the ratio of the area of the football shaped region that is both shaded and striped ($A \\intersect B$) to the area of the shaded circle ($B$).](03-probability_files/figure-html/fig-VennConditional-1.png){#fig-VennConditional width=432}\n:::\n:::\n\n\n<!-- % The example above indicates how we should define conditional probability  -->\n\n<!-- % generally. -->\n\n<!-- % \\todo{Venn Diagram} -->\n\n::: {.boxedText #def-condProb}\n\nLet $A$ and $B$ be two events such that $\\Prob(B) \\neq 0$.\\\nThe \\textbf{conditional probability} of $A$ given $B$ is defined by \n$$\n\\Prob(A \\mid B) = \\frac{\\Prob(A \\intersect B) }{ \\Prob(B) } ; . \n$$ \nIf $\\Prob(B) = 0$, then $\\Prob(A \\mid B)$ is undefined.\n:::\n\n<!-- end boxedText -->\n\n::: {.example #exm-TshirtColor}\nA class of $5$th graders was asked what color should be used for the\nclass T-shirt, red or purple. The table below contains a summary of the\nstudents' responses:\n\n+----------+-------------+--------------+\n|          | Red         | Purple       |\n+----------+-------------+--------------+\n| Girls    | $7$         | $9$          |\n+----------+-------------+--------------+\n| Boys     | $10$        | $8$          |\n+----------+-------------+--------------+\n\n**Q.** Suppose we randomly select a student from this class. Let $R$ be\nthe event that a child prefers a red T-shirt. Let $B$ be the event that\nthe child is a boy, and let $G$ be the event that the child is a girl.\\\nExpress each of the following probabilities in words and determine their\nvalues: \n\n::: {.multicols}\n\n:::: itemize\n1.  $\\Prob(R)$,\n2.  $\\Prob(R \\mid B)$,\n3.  $\\Prob(B \\mid R)$,\n4.  $\\Prob(R \\mid G)$,\n5.  $\\Prob(G \\mid R)$,\n6.  $\\Prob(B \\mid G)$.\n::::\n<!-- end itemize -->\n\n:::\n<!-- end multicols -->\n\n**A.** The conditional probabilities can be computed in two ways. We can\nuse the formula from the definition of conditional probability directly,\nor we can consider the condition event to be a new, smaller sample space\nand read the conditional probability from the table.\n\n:::: {.itemize}\n1.  $\\Prob(R) = 17/34 = 1/2$ because $17$ of the $34$ kids prefer red\n\n    This is the probability that a randomly selected student prefers red\n\n2.  $\\displaystyle \\Prob(R \\mid B) = \\frac{10/34}{18/34} = \\frac{10}{18}$\n    because $10$ of the $18$ boys prefer red\n\n    This is the probability that a randomly selected boy prefers red\n\n3.  $\\displaystyle \\Prob(B \\mid R)= \\frac{10/34}{17/34} = \\frac{10}{17}$\n    because $10$ of the $17$ students who prefer red are boys.\n\n    This is the probability that a randomly selected student who prefers\n    red is a boy.\n\n4.  $\\displaystyle \\Prob(R \\mid G) = \\frac{7/34}{16/34} = \\frac{7}{16}$\n    because $7$ of the $16$ girls prefer red\n\n    This is the probability that a randomly selected girl prefers red\n\n5.  $\\displaystyle \\Prob(G \\mid R) = \\frac{7/34}{17/34} = \\frac{7}{17}$\n    because $7$ of the $17$ kids who prefer red are girls.\n\n    This is the probability that a randomly selected kid who prefers red\n    is a girl.\n\n6.  $\\displaystyle \\Prob(B \\mid G) = \\frac{0}{16/34} = 0$ because\n    none of the girls are boys.\n\n    This is the probability that a randomly selected girl is a boy.\n::::\n<!-- end itemize -->\n\n:::\n\nOne important use of conditional probability is as a tool to calculate\nthe probability of an intersection.\n\n::: {.boxedText #lem-probOfInt}\n\nLet $A$ and $B$ be events with non-zero probability. Then \n\n$$\n\\begin{aligned}\n\\Prob(A \\intersect B) & = \\Prob(A) \\cdot\\Prob(B \\mid A)\n\\\\ & = \\Prob(B) \\cdot\\Prob(A \\mid B) ;.\n\\end{aligned}\n$$\n\nThis follows directly from the definition of conditional probability by\na little bit of algebra and can be generalized to more than two events.\n:::\n\n<!-- end boxedText -->\n\n::: {.example #exm-doubles}\n\n**Q.** If you roll two standard dice, what is the probability of\ndoubles? (Doubles is when the two numbers match.)\n\n**A.** Let $A$ be the event that we get a number between $1$ and $6$ on\nthe first die. So $\\Prob(A) = 1$. Let $B$ be the event that the second\nnumber matches the first. Then the probability of doubles is\n$\\Prob(A \\intersect B) = \\Prob(A) \\cdot\\Prob(B \\mid A) = 1 \\cdot\\frac{1}{6} = \\frac{1}{6}$\nsince regardless of what is rolled on the first die, $1$ of the $6$\npossibilities for the second die will match it.\n:::\n\n::: {.example #exm-flush}\n\n**Q.** A $5$-card hand is dealt from a standard $52$-card deck. What is\nthe probability of getting a flush (all cards the same suit)?\n\n**A.** Imagine dealing the cards in order. Let $A_i$ be the event that\nthe $i$th card is the same suit as all previous cards. Then\n\n$$\n\\begin{aligned}\n\\evProb{flush} & =  \\Prob(A_1 \n  \\intersect  A_2\n  \\intersect  A_3\n  \\intersect  A_4\n  \\intersect  A_5) \\\\\n  & =  \\Prob(A_1) \n    \\cdot \\Prob(A_2 \\mid A_1)\n    \\cdot \\Prob(A_3 \\mid A_1 \\intersect A_2)\n    \\\\ & \\quad\n    \\cdot \\Prob(A_4 \\mid A_1 \\intersect A_2 \\intersect A_3)\n    \\\\ & \\quad\n    \\cdot \\Prob(A_5 \\mid A_1 \\intersect A_2 \\intersect A_3 \\intersect A_4) \\\\\n    & = 1 \\cdot \\frac{12}{51} \\cdot \\frac{11}{50} \\cdot \\frac{10}{49} \n    \\cdot \\frac{9}{48} \\; \n\\end{aligned}\n$$\n:::\n\n\n::: {.example #exm-valentines}\n\n**Q.** In a bowl are 4 red Valentine hearts and 2 blue Valentine hearts.\n\nIf you reach in without looking and select two of the Valentines, let\n$X$ be the number of blue Valentines. Fill in the following probability\ntable.\n\n+:-------------+:----:+:----:+:----:+\n| value of $X$ |  0   | 1    | 2    |\n+--------------+------+------+------+\n| probability  |      |      |      |\n+--------------+------+------+------+\n\n**A.** \n\n$$\n\\begin{aligned}\n\\Prob(X = 2) &= \n\\Prob(\\mbox{first is blue} \\tand \\mbox{second is blue}) \n\\\\\n&= \\Prob(\\mbox{first is blue}) \\cdot \n      \\Prob(\\mbox{second is blue} \\mid \\mbox{first is blue}) \n\\\\\n&= \\frac26 \\cdot \\frac15 \n\\\\\n&= \\frac{2}{30} \\;.\n\\end{aligned}\n$$\n\nSimilarly \n\n$$\n\\begin{aligned}\n\\Prob(X = 0) &= \n\\Prob(\\mbox{first is red} \\tand \\mbox{second is red}) \n\\\\\n&= \\Prob(\\mbox{first is red}) \\cdot \n     \\Prob( \\mbox{second is red} \\mid \\mbox{first is red}) \n\\\\\n&= \\frac46 \\cdot \\frac35 \n\\\\\n&= \\frac{12}{30} \n\\end{aligned}\n$$\n\nFinally, $\\Prob(X = 1) = 1 - \\Prob(X = 0) - \\Prob(X = 2) = 1 - \\frac{14}{30} = \\frac{16}{30}$.\n\nWe can represent this using a **tree diagram** as well.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](03-probability_files/figure-html/unnamed-chunk-12-1.png){width=432}\n:::\n:::\n\n\nThe edges in the tree represent conditional probabilities which we can\nmultiply together to the probability that all events on a particular\nbranch happen. The first level of branching represents what kind of\nValentine is selected first, the second level represents the second\nselection.\n:::\n\n\n{{< pagebreak >}}\n\n\n\n::: {.example #exm-sensitivitySpecificity}\n\n**Q.** Suppose a test correctly identifies diseased people $99$%\nidentifies healthy people $98$% Furthermore assume that in a certain\npopulation, one person in $1000$ has the disease. If a random person is\ntested and the test comes back positive, what is the probability that\nthe person has the disease?\n\n**A.** We begin by introducing some notation. Let $D$ be the event that\na person has the disease. Let $H$ be the event that the person is\nhealthy. Let $+$ be the event that the test comes back positive (meaning\nit indicates disease -- probably a negative from the perspective of the\nperson tested). Let $-$ be the event that the test is negative.\n\n:::: {.itemize}\n*  $\\Prob(D) = 0.001$, so $\\Prob(H) = 0.999$.\n\n*  $\\Prob(+ \\mid D) = 0.99$, so $\\Prob(- \\mid D) = 0.01$.\n\n    $\\Prob(+ \\mid D)$ is called the **sensitivity** of the test. (It\n    tells how sensitive the test is to the presence of the disease.)\n\n*  $\\Prob(- \\mid H) = 0.98$, so $\\Prob(+ \\mid H) = 0.02$.\n\n    $\\Prob(- \\mid H)$ is called the **specificity** of the test.\n    \\smallskip\n\n*  $\\!\\!\\!\\!\\!$\n\n\n\n\n\n$$\n\\begin{aligned}\n\\Prob(D \\mid +) & = \\frac{\\Prob(D \\intersect +)}{\\Prob(+)}\n\\\\[5mm]\n&= \\frac{\\Prob(D) \\cdot \\Prob(+ \\mid D)}{\\Prob(D \\intersect +)  + \n    \\Prob(H \\intersect +)  }\n\\\\[5mm]\n& = \\frac{0.001 \\cdot 0.99}{0.001 \\cdot 0.99 + 0.999 \\cdot 0.02}\n                      =  0.0472\n\\end{aligned}\n$$\n\nA tree diagram is a useful way to visualize these calculations.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](03-probability_files/figure-html/unnamed-chunk-15-1.png){width=432}\n:::\n:::\n\n\nThis low probability surprises most people the first time they see it.\nThis means that if the test result of a random person comes back\npositive, the probability that that person has the disease is less than\n$5$%, even though the test is \"highly accurate\". This is one reason why\nwe do not routinely screen an entire population for a rare disease --\nsuch screening would produce many more false positives than true\npositives.\n\nOf course, if a doctor orders a test, it is usually because there are\nsome other symptoms. This changes the *a priori* probability that the\npatient has the disease.\n@exr-bayesDisease gives you a chance to explore this further.\n\n::::\n:::\n\n\n{{< pagebreak >}}\n\n\n\n### Independence\n\n::: {.boxedText #def-independentEvents}\n\nLet $A$ and $B$ be two events such that $\\Prob(B) = \\Prob(B \\mid A)$.\nSuch events are called **independent**.\n:::\n<!-- end boxedText -->\n\nWhen events are independent, then\n\n$$\n\\Prob(A \\tand B) = \\Prob(A) \\cdot \\Prob(B \\mid A) = \\Prob(A) \\cdot \\Prob(B) \\;.\n$$\nThis makes probability calculations much simpler -- but it only applies\nfor independent events.\n\n::: {.example #exm-doubles}\n\n**Q.** What is the probability of rolling double sixes with standard\n6-sided dice?\n\n**A.** Let $A$ be the event that the first die is a 6 and let $B$ be the\nevent that the second die is a 6. Since $A$ and $B$ are independent,\n$\\Prob(A \\tand B) = \\Prob(A) \\cdot \\Prob(B) = \\frac16 \\cdot \\frac16 = \\frac{1}{36}$.\n:::\n\n::: {.example #exm-5Heads}\n\n**Q.** What is the probability of flipping a coin five times and getting\n5 heads?\n\n**A.** Since each coin toss is independent of the others, the\nprobability of getting five heads is the product of the probabilities of\neach coin coming up heads:\n\n$$ \n\\Prob(\\mbox{5 heads in 5 flips}) = (0.5)^5 = 0.03125 \n$$\n:::\n\n::: {.example #exm-partFailures}\n**Q.** A manufacturer claims that 99% of its parts will still be\nfunctioning properly two years after purchase. If you purchase 10 of\nthese parts, what is the probability that all 10 of them are still\nfunctioning properly two years later (assuming the manufacturer's claim\nis correct)?\n\n**A.** Let $G_i$ be the event that part $i$ is still functioning\nproperly after two years. We want to calculate \n\n$$\n\\Prob(G_1 \\tand G_2\n\\tand\\cdots\\tand G\\_{10});.\n$$\nIf we assume the lifetimes of the parts are independent, then\n\n$$\n\\begin{aligned}\n\\Prob(G_1 \\tand G_2 \\tand\\cdots\\tand G_{10})\n& =\n\\underbrace{.99 \\cdot.99 \\cdot.99 \\cdots.99}_{\\mbox{10 of these}}\n\\\\\n& = .99^{10} \\\\\n& = 0.9043821\\;.\n\\end{aligned}\n$$\n\nThe independence assumption may or may not be valid. That depends on the\nmanufacturing process. For example, if the primary way a part goes bad\nis that the package is dropped during shipping, then if you by a box of\n10 and the first part is bad, they will all be bad. And if the box was\nhandled carefully and never dropped, and the first part used is good,\nthey will likely all be good. So in that extreme case, the probability\nthat all 10 are functioning properly after two years is 99%.\n:::\n\n\n{{< pagebreak >}}\n\n\n\n## Exercises\n\n::: {.problem #exr-freeThrow}\n**Free throw Amy**\n\nAmy is a 92% free throw shooter. If she shoots 100 free throws after\npractice, what is the probability that she makes at least 95 of them?\nUse simulation to estimate this probability.\n\n(You can use `rflip()` to simulate shooting free throws. The `prob`\nargument lets you set the probability. In this case, you need to set it\nto $0.92$. Then think of a head as a made free throw and a tail as a\nmissed free throw.)\n:::\n\n<!-- end problem -->\n\n::: {.solution}\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)    # so we get the same simulated results each time we compile.\nsims <- do(1000) * rflip(100, prob = 0.92)\ntally( ~ heads > 95, data = sims)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nheads > 95\n TRUE FALSE \n   94   906 \n```\n:::\n:::\n\n\nSo the probability that Amy makes more than 95 shots in 100 attempts is\napproximately\n0.094\n:::\n\n<!-- end solution -->\n\n::: {.problem #exr-dice}\n**Dice**\n\n:::: {.enumerate}\n1.  Use simulation to estimate the probability of rolling a difference\n    of 2 when rolling two fair six-sided dice.\n\n2.  Make a histogram showing the results for all of the possible\n    differences.\n::::\n<!-- end enumerate -->\n\n:::\n<!-- end problem -->\n\n::: {.solution}\n\n::: {.cell}\n\n```{.r .cell-code}\nd <- die1 - die2\ntally( ~ d )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nd\n  -5   -4   -3   -2   -1    0    1    2    3    4    5 \n 279  610  765 1092 1409 1634 1423 1165  792  555  276 \n```\n:::\n\n```{.r .cell-code}\nprop( ~ (d == 8) )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nprop_TRUE \n        0 \n```\n:::\n\n```{.r .cell-code}\ngf_histogram( ~ d, binwidth = 1)    # setting width is important for integer data\n```\n\n::: {.cell-output-display}\n![](03-probability_files/figure-html/unnamed-chunk-17-1.png){width=432}\n:::\n:::\n\n:::\n\n<!-- end solution -->\n\n::: {.problem #exr-cards}\n**Cards**\n\nUse simulation to estimate the probability that when dealing 5 cards\nfrom a standard (well-shuffled) deck of 52 cards all five are diamonds.\n\nYou can simulate the deck of cards using the numbers 1 through 52 and\nconsider the numbers 1 through 13 to be the diamonds. Instead of using\n`resample()`, which would allow you to get the same card more than once,\nwe need to use `sample()`, which does not. (You can also use `deal()`\nwhich does the same thing.)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsample(1:52, 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 10 38 43 25 37\n```\n:::\n\n```{.r .cell-code}\nsample(1:52, 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 19 15 36 24 31\n```\n:::\n\n```{.r .cell-code}\ndeal(1:52, 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 46 43 20 29 40\n```\n:::\n\n```{.r .cell-code}\ndeal(1:52, 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 17 24 10 11 37\n```\n:::\n:::\n\n\nThere is another way to make the calculation, using the function\n`sum()`. R can tell you how many cards are below 14 using `sum()`\nbecause R turns TRUE into 1 and FALSE into 0 when you do a sum.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsum( sample(1:52, 5) < 14 ) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2\n```\n:::\n\n```{.r .cell-code}\nsum( sample(1:52, 5) < 14 )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0\n```\n:::\n\n```{.r .cell-code}\nsum( sample(1:52, 5) < 14 )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1\n```\n:::\n:::\n\n\nYou can use `do()` to do this many times. (Three is *not* many! We just\ndo a small number here for illustration purposes.)\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndo(3) * sum( sample( 1:52, 5 ) < 14 )\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"sum\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"0\"},{\"1\":\"0\"},{\"1\":\"1\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n:::\n\n<!-- end problem -->\n\n::: {.solution}\n\n::: {.cell}\n\n```{.r .cell-code}\ntally( ~ sum, do(10000) * sum(sample(1:52, 5) < 14) )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nsum\n   0    1    2    3    4    5 \n2218 3992 2826  853  107    4 \n```\n:::\n:::\n\n:::\n<!-- end solution -->\n\n::: {.problem #exr-manufacturing}\n**Quality control**\n\nParts in a manufacturing plant go through two quality control checks\nbefore they are shipped. 99% of parts pass inspection A and 98% parts\npass inspection B. 0.5% fail both inspections.\n\nWhat percentage of parts pass both inspections?\n:::\n<!-- end problem -->\n\n::: {.solution}\n    $\\Prob(\\mbox{fail at least one}) = \\Prob(\\mbox{fail A or fail B}) =\n    \\Prob(\\mbox{fail A}) + \\Prob(\\mbox{fail B}) - \\Prob(\\mbox{fail both})\n    = 0.01 + 0.02 - 0.05 = 0.025$.\n\n    So $\\Prob(\\mbox{pass both}) = 1 - 0.025 = 0.975$.\n:::\n<!-- end solution -->\n\n::: {.problem #exr-sumOfDice}\n**Sum of dice**\n\nLet $X$ be the sum of the results of rolling two fair six-sided dice.\n\n:::: {.enumerate}\n1.  What is $\\Prob(X \\mbox{ is even} \\tand X < 5)$?\n2.  What is $\\Prob(X \\mbox{ is even} \\tor X < 5)$?\n::::\n\n<!-- end enumerate -->\n:::\n<!-- end problem -->\n\n::: {.solution}\nThe probability that $X$ is even and less than five is \n$\\Prob(X = 2 \\tor X = 4) = 1/36 + 3/36 = 4/36 = 0.1111111$.\n\nThe probability that $X$ is even or less than five is \n$\\Prob(\\mbox{X is even}) + \\Prob(X = 3) = 18/36 + 2/36 = 20/36 = 0.5555556$.\n:::\n<!-- end solution -->\n\n::: {.problem #exr-diffDice}\n**Difference in dice**\n\nLet $Y$ be the difference between the larger and smaller number when two\nfair dice are rolled. (So if you roll a 2 and a 4, then the value of $Y$\nis 2.)\n\n:::: {.enumerate}\n1.  What is $\\Prob(Y = 2)$?\n2.  What are the other possible values of $Y$?\n3.  Calculate the probability for each possible value of $Y$ and put\n    those values in a table.\n::::\n<!-- end enumerate -->\n\n:::\n<!-- end problem -->\n\n::: {.solution}\n$Y = 2$ for rolls of $(3,1)$, $(4,2)$, $(5,3)$, and $(6,4)$. Each of\nthese can also happen in the other order, so the probability is\n$8/36 = 2/9 = 0.2222222$.\n\n:::: {.center}\n::::: {.tabular}\n        TEX COMMAND NOT FOUND hline         value of $Y$ & 0 & 1 & 2 & 3 & 4 & 5 \\\\\n        TEX COMMAND NOT FOUND hline         probability & 6/36 & 10/36 & 8/36 & 6/36 & 4/36 & 2/36 \\\\\n        TEX COMMAND NOT FOUND hline     ::: \n\n:::::\n<!-- end tabular -->\n::::\n<!-- end center -->\n\n\n::: {.cell}\n\n```{.r .cell-code}\nc(6,10,8,6,4,2) / 36\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.16666667 0.27777778 0.22222222 0.16666667 0.11111111 0.05555556\n```\n:::\n:::\n\n:::\n<!-- end solution -->\n\n::: {.problem #exr-kids}\n**Kids**\n\nFor the probabilities below, you may assume the that for each birth, the\nprobability of having a boy or a girl is $1/2$ and that each birth is\nindependent of other births.\n\n:::: {.enumerate}\n1.  Suppose a family has three kids. What is the probability that at\n    least one of the kids is a boy?\n2.  Suppose a family has three kids, at least one of which is a girl.\n    Now what is the probability that at least one of the kids is a boy?\n3.  Suppose a family has three kids, at least two of which are girls.\n    Now what is the probability that at least one of the kids is a boy?\n::::\n<!-- end enumerate -->\n:::\n<!-- end problem -->\n\n::: {.problem #exr-device-with-two-parts}\n**A device with two parts\n\nA device is assembled from two primary parts. 2% of the first type of\npart are defective and 3% of the other type of part are defective. The\ndevice only functions properly if both parts are functioning properly.\n\n:::: {.enumerate}\n1.  What assumption do you need to make to calculate the probability\n    that a device assembled in this way will function properly? Is it a\n    reasonable assumption in this situation? Explain.\n\n2.  What is the probability that that a device assembled in this way\n    will function properly?\n::::\n<!-- end enumerate -->\n\n:::\n<!-- end problem -->\n\n::: {.solution}\nAssuming failure of each part is independent of failure of the other,\nthe probability that both function properly is \n$0.98 \\cdot 0.97 = 0.9506$.\n\nAlternatively, if we assume that failures are mutually exclusive, then\nthe probability of failure would be $0.02 + 0.03 = 0.05$ and the\nprobability of proper functioning would be $0.95$.\n\nThe independence assumption is reasonable if, for example, the two parts\nare made by separate manufacturing processes and the device is assembled\nby randomly selecting a part of each type, which may or may not be a\ngood part right from the start.\n\nThe mutually exclusive failure is probably harder to justify, since\nlikely there will be some situations in which both parts fail.\n:::\n<!-- end solution -->\n\n::: {.problem #exr-bayesDisease}\n**Testing for a disease, revisited**\n\nIn the situation of Example @exm-sensitivitySpecificity, how does\nthe answer change if the baseline probability of having the disease is\n$1/10$ instead of $1/1000$? (This might be the case if a person is\nexhibiting symptoms, for example.)\n:::\n<!-- end problem -->\n\n::: {.solution}\n\n::: {.cell}\n\n```{.r .cell-code}\n# P(D) = 0.001\n0.001 * 0.99 / (0.001 * 0.99 + 0.999 * 0.02)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.0472103\n```\n:::\n\n```{.r .cell-code}\n# P(D) = 0.10\n0.1 * 0.9 / (0.10 * 0.99 + 0.9 * 0.02)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.7692308\n```\n:::\n:::\n\n:::\n\n<!-- end solution -->\n\n::: {.problem #exr-smokers}\n**Smoking and lung cancer**\n\nAccording to the CDC, \"Compared to nonsmokers, men who smoke are about\n23 times more likely to develop lung cancer and women who smoke are\nabout 13 times more likely.\" According to the American Lung Association:\n\"In 2008, 21.1 million (18.3%) women smoked in the United States\ncompared to 24.8 million (23.1%) men.\"\n\n:::: {.enumerate}\n1.  If you learn that a person is a smoker and no nothing else about the\n    person, what is the probability that the person is a woman?\n\n2.  If you learn that a woman has been diagnosed with lung cancer, and\n    you know nothing else about her, what is the probability that she is\n    a smoker?\n\n3.  If you learn that a man has been diagnosed with lung cancer, and you\n    know nothing else about him, what is the probability that he is a\n    smoker?\n::::\n<!-- end enumerate -->\n\n:::\n\n<!-- end problem -->\n\n::: {.solution}\n\n::: {.cell}\n\n```{.r .cell-code}\n# a)\n21.1 / ( 21.1 + 24.8)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.459695\n```\n:::\n:::\n\n\nPart b is the most interesting (once you can do that, you can do part c\nthe same way). Let $W$ be the event that someone is a woman, $S$ that\nthey are a smoker, and $C$ that they get cancer. Let\n$x = \\Prob( C | W \\intersect S^c)$. Then\n$\\Prob( C | W \\intersect S ) = 13x$.\n\n$$\n\\begin{aligned}\n    \\Prob( S | W \\intersect C ) \n    & = \\frac{ \\Prob(S \\intersect W \\intersect C) }{\\Prob(W \\intersect C)}\n    \\\\\n    & = \\frac{ \\Prob(S \\intersect W \\intersect C) }\n    {\\Prob(S \\intersect W \\intersect C) + \\Prob( S^c \\intersect W \\intersect C)}\n\\end{aligned}\n$$\n\nSo we just need to compute the two probabilities in the denominator.\n\n$$\n\\begin{aligned}\n    \\Prob(S \\intersect W \\intersect C)\n    &= \\Prob(W) \\cdot \\Prob(S \\mid W) \\cdot \\Prob(C \\mid W \\intersect S) \n    \\\\\n    &= \\Prob(W) \\cdot 0.183 \\cdot 13x\n    \\\\\n    \\Prob(S^c \\intersect W \\intersect C)\n    &= \\Prob(W) \\cdot \\Prob(S^c \\mid W) \\cdot \\Prob(C \\mid W \\intersect S^c) \n    \\\\\n    &= \\Prob(W) \\cdot 0.817 \\cdot x\n\\end{aligned}\n$$\n\nAfter factoring out $x \\cdot \\Prob(W)$, the arithmetic is now easy:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# b) After factoring out a constant from numerator and denominator we are left with\n0.183 * 13 / ( 0.183 * 13 + .817 * 1 )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.744368\n```\n:::\n\n```{.r .cell-code}\n# c) After factoring out a constant from numerator and denominator we are left with\n0.231 * 23 / ( 0.231 * 23 + .769 * 1 )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.8735613\n```\n:::\n:::\n\n\nNote: Another approach to part b is to consider the sample space to be\nonly the women. If you do it that way, you can avoid mentioning any\nprobabilities involving $W$. (In the end, they factor out anyway.) Of\ncourse, you can do a similar thing for the men.\n:::\n<!-- end solution -->\n\n::: {.problem #exr-bad-parts-by-day}\n**Parts by day**\n\nA manufacturing plant has kept records that show that the number of\nparts produced each day and on the proportion of parts that are\ndefective.\n\n\n```{=tex}\n\\begin{center}\n\\begin{tabular}{|lrrrr|}\n    \\hline\n    & Monday & Tuesday & Wednesday & Thursday \\\\\n    \\hline\n    Proportion of weekly production & 20% & 25% & 28% & 27% \n    \\\\\n    Rate of defective parts & 2% & 1.5% & 1%  & 3% \n    \\\\\n    \\hline\n\\end{tabular}\n\\end{center}\n```\n\n:::: {.enumerate}\n1.  If you order a part from this company, what is the probability that\n    it was produced on a Monday or a Thursday?\n2.  If you order a part from this company and it is defective, what is\n    the probability that it was produced on a Monday or a Thursday?\n3.  If you order a part from this company and it functions properly,\n    what is the probability that it was produced on a Monday or\n    Thursday?\n::::\n<!-- end enumerate -->\n\nExpress your answers to 3 significant digits and avoid internal\nrounding.\n:::\n<!-- end problem -->\n\n::: {.solution}\nYou may find a tree diagram useful here to visualize these\nprobabilities.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# part a\n.20 + .27\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.47\n```\n:::\n\n```{.r .cell-code}\n# part b: P( Wed-Thur | defective ) = P( Wed-Thur and defective ) / P(defective)\na <- .20 * .02 +       # Monday and defective\n     .27 * .03         # Thursday and defective\nb <- .25 * .015 +      # Tuesday and defective\n     .28 * .01         # Wednesday and defective \na / (a + b)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.6487936\n```\n:::\n\n```{.r .cell-code}\n# part c: P( Wed-Thur | good ) = P( Wed-Thur and good ) / P(good)\nc <- .20 * .98 +       # Monday and good\n     .27 * .97         # Thursday and good\nd <- .25 * .985 +      # Tuesday and good\n     .28 * .99         # Wednesday and good \nc / (c + d)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.4666021\n```\n:::\n:::\n\n:::\n<!-- end solution -->\n\n<!-- % \\begin{problem} -->\n\n<!-- % %% modified from -->\n\n<!-- % %% http://allendowney.blogspot.com/2011/10/my-favorite-bayess-theorem-problems.html -->\n\n<!-- % %% Note: not a Bayes Theorem probelm -->\n\n<!-- % John had a twin brother who died at birth.   -->\n\n<!-- % What is the probability that John was an identical twin? -->\n\n<!-- %  -->\n\n<!-- % To answer this one, you need some background information.  -->\n\n<!-- % According to a Wikipedia article on twins:   -->\n\n<!-- % ``Twins are estimated to be approximately 1.9% of the world population,  -->\n\n<!-- % with monozygotic [identical] twins making up 0.15% of the total popultion---and 8%  -->\n\n<!-- % of all twins.'' -->\n\n<!-- % \\end{problem} -->\n\n::: {.problem #exr-acceptanceSampling}\n**Acceptance sampling**\n\nAn engineer orders a shipment of 100 indentical parts.\\\nBefore accepting the shipment, he tests three of them.\\\nIf the they all test good, he accepts the entire shipment.\\\nIf any of them tests bad, he rejects the shipment.\n\nGiven the good price he has gotten on these parts, the engineer would be\nsatisfied if at least 95%\n\n:::: {.enumerate}\n1.  Suppose that there are 5 bad parts in the shipment. What is the\n    probability that the shipment is rejected (even though the engineer\n    would actually have been satisfied with the shipment)?\n2.  Suppose that there are 10 bad parts in the shipment. What is the\n    probability that the shipment is accepted (even though the engineer\n    would not be satisfied with this shipment)?\n::::\n<!-- end enumerate -->\n\n:::\n<!-- end problem -->\n\n::: {.solution}\n:::: {.enumerate}\n1.  The engineer will accept if all three are among the 95 good parts.\n    The probability of accepting is\n\n\n::: {.cell}\n\n```{.r .cell-code}\n95/100 * 94/99 * 93/98\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.8559988\n```\n:::\n:::\n\n\nThe probability of rejecting is\n\n\n::: {.cell}\n\n```{.r .cell-code}\n1 - 95/100 * 94/99 * 93/98\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.1440012\n```\n:::\n:::\n\n\n1.  Now we accept if all three are among the 90 good parts. The\n    probability of accepting is\n\n\n::: {.cell}\n\n```{.r .cell-code}\n90/100 * 89/99 * 88/98\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.7265306\n```\n:::\n:::\n\n::::\n<!-- end enumerate -->\n\nWe see that this is not the most effective test. It could be improved by\ntaking a larger sample, and similar arithmetic could be used to\ndetermine how well a new protocol works (perhaps one that takes a larger\nsample).\n:::\n<!-- end solution -->\n\n::: {.problem #exr-MM}\n**M&M's**\n\n<!-- %% http://allendowney.blogspot.com/2011/10/my-favorite-bayess-theorem-problems.html -->\nThe blue M&M was introduced in 1995.\nBefore then, the color mix in a bag of plain M&Ms was 30% Brown, 20%\nYellow, 20% Red, 10% Green, 10% Orange, 10% Tan.\nAfterward it was 24% Blue , 20% Green, 16% Orange, 14% Yellow, 13% Red,\n13% Brown.\n\nA friend of mine has two bags of M&Ms, and he tells me that one is from\n1994 and one from 1996. He won't tell me which is which, but he gives me\none M&M from each bag. One is yellow and one is green.\nWhat is the probability that the yellow M&M came from the 1994 bag?\n:::\n<!-- end problem -->\n\n::: {.solution}\nLet's use the following notation for events related to this problem:\n<!-- begin itemize --> \n:::: {.itemize} \n\n1. $G_4 =$ green from 1994 bag\n2. $G_6 =$ green from 1996 bag \n3. $Y_4 =$ yellow from 1994 bag \n4. $Y_6 =$ yellow from 1996 bag \n\n:::: \n<!-- end itemize -->\n\nThen our question becomes \n$$\n\\begin{aligned}\n\\Prob( Y_4 \\tand G_6 \\mid \n       (Y_4 \\tand G_6) \\tor (Y_6 \\tand G_4) )\n       & =\n\\frac{\\Prob( Y_4 \\tand G_6 ) }\n     {\\Prob( Y_4 \\tand G_6) \\tor (Y_6 \\tand G_4)}\n\\\\\n& = \\frac{\\Prob( Y_4 \\tand G_6 ) }\n     {\\Prob(Y_4 \\tand G_6) + \\Prob(Y_6 \\tand G_4)}\n\\end{aligned}\n$$\n\nThe individual probabilities can be worked out as \n$$\n\\Prob(Y_4 \\tand\nG_6) = \\Prob(Y_4) \\cdot \\Prob(G_6 \\mid Y_4) = .20 \\cdot .20 = 0.04 \n$$\n\n$$\n\\Prob(Y_6 \\tand G_4) = \\Prob(Y_6) \\cdot \\Prob(G_4 \\mid Y_6) = .14\n\\cdot .10 = 0.014 \n$$\n\nPutting this all together we get\n\n\\% O: .20 Y, .10 G % N: .14 Y, .20 G\n\n\n::: {.cell}\n\n```{.r .cell-code}\n.20 * .20 / (.20 * .20 + .14 * .10) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.7407407\n```\n:::\n:::\n\n\nA tree diagram could be used to depict these probabilities as well.\n:::\n<!-- end solution -->\n\n![](images/cigarettes-cartoon.png){fig-align=\"center\"}\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}