\Sexpr{set_parent('STAT241-S19.Rnw')}

\Chapter{Numerical Summaries}

\section{Tabulating Data}
A table is one kind of numerical summary of a data set.  In fact, you can think of histograms
and bar graphs as graphical representations of summary tables.  But sometimes it is nice to
have the table itself.  \R\ provides several ways of obtaining such tables.

\subsection{Tabulating a categorical variable}

\subsubsection*{The formula interface}

There are several functions for tabulating categorical variables.  
\function{tally()}  uses a syntax that is very similar to \function{bargraph()}.    
We'll call this method the \term{formula interface}.
(\R\ calls anything with a tilde (\code{\~}) a formula.)
<<xtabs>>=
tally( ~ substance, data=HELPrct )
tally( ~ substance, data=HELPrct, format="prop" )
tally( ~ substance, data=HELPrct, format="perc" )
@

\subsubsection*{The \$-interface}
\function{table()} and its cousins use the \code{\$} operator which selects one variable out of a 
data frame.
<<dollar-sign,tidy=FALSE>>=
KidsFeet$sex      # general syntax: dataframe$variable
@
We'll call this interface the \code{\$}-interface.
\Rindex{perctable}%
\Rindex{proptable}%
<<table>>=
table( HELPrct$substance )
perctable( HELPrct$substance )     # display percents instead of counts
proptable( HELPrct$substance )     # display proportions instead of counts
@

\subsubsection*{Two interfaces}
Some functions in \R\ require the formula interface, some require the
\code{\$}-interface, and some allow you to use either one.%
\footnote{One of the things that the \pkg{mosaic} package does is provide a
formula interface for many functions that only had a \code{\$}-interface
before.}
For example, histogram will also work like this.
<<histogram-dollar>>=
gf_histogram( ~HELPrct$age )
@
But notice that the output is not quite as nice, since the default label 
for the horizontal axis now shows both the data frame name and the variable name
with a \code{\$} between.  
\emph{My advice is to use formula interfaces whenever they are 
available.}

\subsection{Tabulating a quantitative variable}

Although \function{tally()} and \function{table()} work with quantitative variables
as well as categorical variables, this is only useful when there are not too
many different values for the variable.

<<xtabs-quantitative>>=
tally( ~age, data=HELPrct )
@

\subsubsection*{Tabulating in bins (optional)}
Usually a graph is the best way to display and summarize quantitative data, but if you need to creat a summary table, you may need to group quantitative data into bins.  We just have to tell \R\ what the bins are.
For example, suppose we wanted to group the 20s, 30s, 40s, etc. together.
\Rindex{cut()}%
\Rindex{xtabs()}%
\Rindex{mtable()}%
\Rindex{table()}%
<<cut>>=
# let's add a new variable to HELPrct
HELPrct <- HELPrct %>%
  mutate(binnedAge = cut(age, breaks=c(10,20,30,40,50,60,70) ))
head(HELPrct)
tally( ~binnedAge, data=HELPrct ) 
table( HELPrct$binnedAge)        
@
That's not quite what we wanted: 30 is in with the 20s, for example.
Here's how we fix that.

<<cut2, tidy=FALSE>>=
HELPrct <- HELPrct %>%
  mutate(binnedAge = cut(age, breaks=c(10,20,30,40,50,60,70), right=FALSE) )
tally( ~binnedAge, data=HELPrct )   
table( HELPrct$binnedAge)
@


We won't use this very often, since typically seeing this information in a histogram is 
more useful.  

\subsection{Cross-tables: Tabulating two or more variables}

\function{tally()} can also compute cross tables for two (or more) variables.
<<xtabs-2way>>=
tally(~ sex + substance, data=HELPrct)
@

\section{Working with Pre-Tabulated Data}

Sometimes data arrive pre-tabulated.  We can use \function{gf_col()} instead
of \function{gf_bar()} to graph pre-tabulated data.

<<teen-deaths>>=
require(abd)           # data sets from Analysis of Biological Data
TeenDeaths
gf_col(deaths ~ cause, data=TeenDeaths) %>%
  gf_refine(coord_flip())
@

Notice that by default the causes are displayed in alphabetical order.  \R\
assumes that categorical data is nominal (that is, there is no particular natural or logical ordering to the categories) unless you say otherwise.

Here is an easy way to have things appear in a different order. The causes of death are reordered in order of increasing number of \variable{deaths} caused.
<<teen-deaths-order>>=
gf_col( deaths ~ fct_reorder(cause,deaths), data=TeenDeaths) %>%
  gf_refine(coord_flip()) %>%
  gf_labs(x = 'Cause of Death', y = 'Number of Deaths')
@


\section{Summarizing Distributions of Quantitative Variables}
\subsubsection*{Important Note}
Numerical summaries are a convenient way to 
describe a distribution, but remember that numerical summaries 
do not necessarily tell you everything there is to know about a distribution.  When working with a new dataset, it is \emph{always} important to explore the data as fully as possible (commonly including graphical as well as numerical summaries, and sometimes even examining the data table directly) before accepting any simplified summary as a good representation of the data.  You might discover certain patterns in the data, interesting features, or even outliers or mistakes in the data, that make certain summaries misrepresentations of the whole.

\subsubsection*{Notation}
In statistics $n$ (or sometimes $N$) almost always means the number 
of observations (i.e., the number of rows in a data frame).

If $y$ is a variable in a data set with $n$ cases, we 
can denote the $n$ values of $y$ as 
\begin{itemize}
\item
$y_1, y_2, y_3, \dots, y_n$ (in the original order of the data).
\item
$y_{(1)}, y_{(2)}, y_{(3)}, \dots y_{(n)}$ (in sorted order from smallest to largest).

\end{itemize}

The symbol $\displaystyle \sum$ represents summation (adding up a bunch of values).

\section{Measures of Center}
Measures of center attempt to give us a sense of what is a
typical value for the distribution.

%\subsection{Mean}

\begin{align*}
\mbox{mean of $y$} 
&=
\mean{y}
= \frac{\displaystyle \sum_{i=1}^{n} y_i}{n}
= \frac{\mbox{sum of values}}{\mbox{number of values}}  
\\[3mm]
\mbox{median of $y$}
&=
\mbox{the ``middle'' number (after putting the numbers in increasing order)
} 
\end{align*}

\begin{itemize}
\item
The mean is the ``balancing point'' of the distribution.
\item
The median\footnote{A note about calculating medians: If the number of datapoints is odd, the median is the middle value (after putting the observations in increasing order). In cases where there is an even number of observations, the median is the
  average of the middle two observations.} is the 50th percentile: half of the distribution is below the median,
half is above.
\item
If the distribution is symmetric, then the mean and median are the same.
\item
In a skewed distribution, the mean is pulled farther toward the tail than the median is.
\item
\emph{A few very large or very small values can change the mean a lot,}
so the mean is \term{sensitive to outliers} and is a better measure of center
when the distribution is symmetric than when it is skewed.
\item
The median is a \term{resistant measure} (resistant to the presence of outlier) -- it is not affected much by a few very large or very small values.
\end{itemize}


%\subsection{Median}

\section{Measures of Spread}

\begin{align*}
\mbox{variance of $y$} 
= s^2_y 
&= 
\frac{\displaystyle \sum_{i=1}^{n} (y_i - \mean y)^2 }{n-1}
\\[4mm]
\mbox{standard deviaiton of $y$} = s_y 
&= \sqrt{s^2_y} 
\\
&= \mbox{square root of variance}
\\[4mm]
\mbox{interquartile range} = \mbox{IQR}
&= Q_3 - Q_1 
\\
& = \mbox{difference between first and third quartiles (defined shortly)}
\end{align*}

\begin{itemize}
\item
Roughly, the standard deviation is the ``average deviation from the mean".  (That's not
exactly right because of the squaring involved and because we are dividing
by $n-1$ instead of by $n$.  More on that denominator later.)  
\item
The mean and standard deviation are especially useful for describing 
\term{normal distributions} and other unimodal, symmetric distributions that
are roughly ``bell-shaped''.  (We'll learn more about normal distributions later.)
\item
Like the mean, the variance and standard deviation are 
sensitive to outliers and less suited for summarizing skewed distributions.
\item
It is perhaps of some value to compute the variance and standard deviation by hand
once or twice to make sure you understand how these measures are defined, but we will
typically let \R\ do the calculations for us.
\end{itemize}

To get a numerical summary of a variable (a statistic), we need to tell 
\R\ which statistic we want and the variable and data frame involved.  
There several ways we can do this in \R.  
Here are several ways to get the mean, for example:
\Rindex{mean()}%
<<mean,tidy=FALSE>>=
mean(HELPrct$age)          # this is the old fashioned way
mean(~age, data=HELPrct)   # similar to our plotting methods; only works for some functions
@
Using the formula style, we can now compute several different statistics.
\Rindex{sd()}%
\Rindex{var()}%
<<stats1>>=
mean(~ age, data=HELPrct)
sd(~ age, data=HELPrct)
var(~ age, data=HELPrct)
@
\Rindex{median()}%
\Rindex{IQR()}%
\Rindex{favstats()}%
<<stats2>>=
median(~ age, data=HELPrct)
IQR(~ age, data=HELPrct)       
favstats(~ age, data=HELPrct)  # this computes several statistics at once
@

It is also possible to compute these statistics separately for each of several groups.
The syntax is much like the the syntax we used when plotting.  In fact, we have two 
choices for the formula:  \verb!y ~ x! or \verb! ~ x | z!.

<<>>=
mean(age ~ sex, data=HELPrct)
sd(age ~ sex, data=HELPrct)
favstats( ~ age | sex, data=HELPrct )
@

\subsection{A word of caution}
None of these measures (especially the mean and median) 
is a particularly good summary of a set of data if the distribution of the data is not unimodal.  
The histogram below shows the lengths of eruptions of the Old Faithful geyser
at Yellowstone National Park.
<<faithful,fig.width=6,fig.height=2.0,tidy=FALSE>>=
favstats(~ Duration, data=oldfaith)
gf_histogram( ~ Duration, data=oldfaith,  bins=20) %>% 
	gf_labs(title="Old Faithful Eruption Times", x="duration (sec)") 
@
Notice that the mean and median do not represent typical eruption times very well.  
Nearly all eruptions are either quite a bit shorter or quite a bit longer.  
(This is especially true of the mean.)


\subsection{Box plots}

Boxplots (also called box-and-whisker plots) are a graphical representation of a 
\term{5-number summary} of a quantitative variable.  The five numbers are
the five \term{quantiles}:
\begin{itemize}
	\item $Q_0$, the minimum
	\item $Q_1$, the first quartile (25th percintile) 
	\item $Q_2$, the median (50th percentile)
	\item $Q_3$, the third quartile (75th percentile)
	\item $Q_4$, the maximum
\end{itemize}
<<bwplot>>=
gf_boxplot(~age, data=HELPrct)
@

Boxplots provide a way of comparing multiple groups that is especially informative and visually effective.  Here is one way to make boxplots of multiple groups (it 
should look familiar from what we know about histogram):
<<bwplot1>>=
gf_boxplot(~age | substance, data=HELPrct)
@
But \function{gf_boxplot()} has a better way.  Put the quantitative variable on one side of the
wiggle and the categorical on the other.  The placement determines which goes along the 
vertical axis and which along the horizontal axis -- just like it did for \function{gf_point()}.
<<bwplot2>>=
gf_boxplot(substance ~ age, data=HELPrct)
gf_boxplot(age ~ substance, data=HELPrct)
@

And we can combine this idea with conditioning. Careful: The quantitative variable must be the ``y" variable in the formula.

<<bwplot3>>=
gf_boxplot(age ~ substance | homeless, data=HELPrct)
@

\subsection{Small data sets}
When we have relatively small data sets, it may not make sense to use a boxplot.  With very few observations, boxplots can be misleading, in that they suggest the presence of more observations than are really contained in the dataset.  
In these cases, it is better to 
display all the data.  \function{gf_jitter()} allows you to put a categorical variable along one axis and a quantitative variable along the other.  
For some data sets, either option can produce a plot that gives a good picture
of the data.
<<xyplot-quant-by-cat,fig.height=1.5>>=
gf_jitter( weight ~ sex, data=Mosquitoes, width=0.1)
gf_boxplot( weight ~ sex, data=Mosquitoes)
@

Note the effect of the \code{width} argument -- \function{gf_jitter()} moves each data point slightly up or down, to reduce overplotting (data points being plotted exactly on top of one another) and make it clearer how many data-points were observed for each possible combination of x- and y-values. The \code{width} input controls the amount of ``jittering."

\section{Summarizing Categorical Variables}

The most common summary of a categorical variable is the \term{proportion} 
of observations in each category. For a single category:
\begin{align*}
\hat p & = \frac{\mbox{number in one category}}{n}
\end{align*}
Proportions can be expressed as fractions, decimals or percents.  
For example, if there are 
10 observations in one category and $n=50$ observations in all, then 
\[
\hat p = \frac{10}{25} = \frac{2}{5} =  0.40 = 40\%
\]

If we code our categorical variable using 1 for observations in a
single category of interst -- ``the one category" --
and 0 for observations in any other category, then
\emph{a proportion is a sample mean}.

\[
\frac{ 1 + 1 + 1 + 1 + 1 + 1 + 1 + 1 + 1 + 1 + 
0 + 0 + 0 + 0 + 0 + 0 + 0 + 0 + 0 + 0 + 0 + 0 + 0 + 0 + 0 }{25} = \frac{10}{25}
\]

\section{Relationships Between Two Variables}

It is also possible to give numerical summaries of the relationship
between two variables.  The most common one is the \term{correlation coefficient},
which we will learn about later.

\newpage
\section*{Practice Exercises}

\begin{problem}
	Create a data set with $n=6$ values, each an integer between 0 and 10 (inclusive) 
	that has the smallest possible variance.  
	Compute the mean and variance of this data set ``by hand''
	(that is, without using \function{mean()} or \function{sd()} or \function{var()} 
	in \R\ or similar
	features on a calculator).
\end{problem}

\begin{solution}
	The variance will be smallest if all the values are equal to the mean value.
	In that case the variance will be 0.

	If you require all of the numbers to be distinct, the best you can do is 
	6 consecutive numbers
<<>>=
x <- 1:6
mean(~x)
sd(~x)
@
\end{solution}

\begin{problem}
	Create a data set with $n=6$ values, each an integer between 0 and 10 (inclusive) 
	that has the largest possible variance.  
	Compute the variance of this data set ``by hand''
	(that is, without using \function{mean()} or \function{sd()} or 
	\function{var()} in \R\ or similar features on a calculator).
\end{problem}

\begin{solution}
	The variance will be smallest if all the values are far from the mean.
	If we have a data set with three 0's and 3 10's, then the mean is 5 and the 
	variance is
<<>>=
( 3*(0-5)^2 + 3*(10-5)^2 ) / 5
@
	If you require the numbers to be distinct, then the best we can do is
<<>>=
x <- c(0,1,2,8,9,10)
mean(~x)
sd(~x)
@
\end{solution}

\begin{problem}
	Create side-by-side boxplots of the variable \variable{i1} (average number of
	drinks per day) comparing the different \variable{substance} groups
	in the \dataframe{HELPrct} data frame.

	For each \variable{substance} group, explain how you can tell from the 
	boxplots whether the mean will be larger than the median or the median 
	larger than the mean.
\end{problem}

\begin{solution}
<<>>=
gf_boxplot(i1 ~ substance , data=HELPrct)
@
	The means are larger because the distributions have longer tails in the 
	higher direction.  
\end{solution}

\begin{problem}
	Compute the mean and median values of \variable{i1} (average number of
	drinks per day) for each of the \variable{substance} groups in the 
	\dataframe{HELPrct} data frame.
\end{problem}

\begin{solution}
<<>>=
mean(i1 ~ substance, data=HELPrct)
median(i1 ~ substance, data=HELPrct)
@
\end{solution}

\shipoutProblems

\ifsolutions
\ifsolutionslocal
\newpage
\section*{Solutions}
\shipoutSolutions
\fi
\fi
